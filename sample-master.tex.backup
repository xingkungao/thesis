
%% 使用 njuthesis 文档类生成南京大学学位论文的示例文档
%%
%% 作者：胡海星，starfish (at) gmail (dot) com
%% 项目主页: http://haixing-hu.github.io/nju-thesis/
%%
%% 本样例文档中用到了吕琦同学的博士论文的提高和部分内容，在此对他表示感谢。
%%
\documentclass[master]{njuthesis}
%% njuthesis 文档类的可选参数有：
%%   nobackinfo 取消封二页导师签名信息。注意，按照南大的规定，是需要签名页的。
%%   phd/master/bachelor 选择博士/硕士/学士论文

% 使用 blindtext 宏包自动生成章节文字
% 这仅仅是用于生成样例文档，正式论文中一般用不到该宏包
\usepackage[math]{blindtext}


\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

%\captionsetup{compatibility=false}
%\usepackage{graphicx,subfigure}
\usepackage{filecontents}
\usepackage{tkz-tab}
%\usepackage{subfig}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{sistyle}
\SIthousandsep{,}
\usepackage{ascii}
\usepackage[T1]{fontenc}
\usepackage{booktabs}% http://ctan.org/pkg/booktabs
\usepackage{makecell}% http://ctan.org/pkg/makecell
\usepackage{tabularx}
\usepackage{bm}
%\newtheorem{observation}[theorem]{\textbf{事实}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置《国家图书馆封面》的内容，仅博士论文才需要填写

% 设置论文按照《中国图书资料分类法》的分类编号
\classification{0175.2}
% 论文的密级。需按照GB/T 7156-2003标准进行设置。预定义的值包括：
% - \openlevel，表示公开级：此级别的文献可在国内外发行和交换。
% - \controllevel，表示限制级：此级别的文献内容不涉及国家秘密，但在一定时间内
%   限制其交流和使用范围。
% - \confidentiallevel，表示秘密级：此级别的文献内容涉及一般国家秘密。
% - \clasifiedlevel，表示机密级：此级别的文献内容涉及重要的国家秘密 。
% - \mostconfidentiallevel，表示绝密级：此级别的文献内容涉及最重要的国家秘密。
% 此属性可选，默认为\openlevel，即公开级。
\securitylevel{\controllevel}
% 设置论文按照《国际十进分类法UDC》的分类编号
% 该编号可在下述网址查询：http://www.udcc.org/udcsummary/php/index.php?lang=chi
\udc{004.72}
% 国家图书馆封面上的论文标题第一行，不可换行。此属性可选，默认值为通过\title设置的标题。
\nlctitlea{数据中心}
% 国家图书馆封面上的论文标题第二行，不可换行。此属性可选，默认值为空白。
\nlctitleb{网络模型研究}
% 国家图书馆封面上的论文标题第三行，不可换行。此属性可选，默认值为空白。
\nlctitlec{}
% 导师的单位名称及地址
\supervisorinfo{南京大学计算机科学与技术系~~南京市栖霞区仙林大道163号~~210023}
% 答辩委员会主席
\chairman{张三丰~~教授}
% 第一位评阅人
\reviewera{阳顶天~~教授}
% 第二位评阅人
\reviewerb{张无忌~~副教授}
% 第三位评阅人
\reviewerc{黄裳~~教授}
% 第四位评阅人
\reviewerd{郭靖~~研究员}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的中文封面

% 论文标题，不可换行
\title{数据中心网络模型研究}
% 如果论文标题过长，可以分两行，第一行用\titlea{}定义，第二行用\titleb{}定义，将上面的\title{}注释掉
% \titlea{半轻衰变$D^+\to \omega(\phi)e^+\nu_e$的研究}
% \titleb{和弱衰变$J/\psi \to D_s^{(*)-}e^+\nu_e$的寻找}

% 论文作者姓名
\author{高兴坤}
% 论文作者联系电话
\telphone{13951785456}
% 论文作者电子邮件地址
\email{xingkungao@163.com}
% 论文作者学生证号
\studentnum{MG1533012}
% 论文作者入学年份（年级）
\grade{2015}
% 导师姓名职称
\supervisor{唐杰~~副教授}
% 导师的联系电话
\supervisortelphone{13813950617}
% 论文作者的学科与专业方向
\major{计算机科学与技术}
% 论文作者的研究方向
\researchfield{大数据与分布式计算}
% 论文作者所在院系的中文名称
\department{计算机科学与技术系}
% 论文作者所在学校或机构的名称。此属性可选，默认值为``南京大学''。
\institute{南京大学}
% 论文的提交日期，需设置年、月、日。
\submitdate{2018年5月10日}
% 论文的答辩日期，需设置年、月、日。
\defenddate{2018年6月1日}
% 论文的定稿日期，需设置年、月、日。此属性可选，默认值为最后一次编译时的日期，精确到日。
%% \date{2013年5月1日}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的英文封面

% 论文的英文标题，不可换行
\englishtitle{A Research on Network Infrastructures for Data Centers}
% 论文作者姓名的拼音
\englishauthor{GAO Xing-Kun}
% 导师姓名职称的英文
\englishsupervisor{Associate Professor Tang Jie}
% 论文作者学科与专业的英文名
\englishmajor{Computer Science and Techonology}
% 论文作者所在院系的英文名称
\englishdepartment{Department of Computer Science and Technology}
% 论文作者所在学校或机构的英文名称。此属性可选，默认值为``Nanjing University''。
\englishinstitute{Nanjing University}
% 论文完成日期的英文形式，它将出现在英文封面下方。需设置年、月、日。日期格式使用美国的日期
% 格式，即``Month day, year''，其中``Month''为月份的英文名全称，首字母大写；``day''为
% 该月中日期的阿拉伯数字表示；``year''为年份的四位阿拉伯数字表示。此属性可选，默认值为最后
% 一次编译时的日期。
\englishdate{May 1, 2018}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的中文摘要

% 设置中文摘要页面的论文标题及副标题的第一行。
% 此属性可选，其默认值为使用|\title|命令所设置的论文标题
% \abstracttitlea{数据中心网络模型研究}
% 设置中文摘要页面的论文标题及副标题的第二行。
% 此属性可选，其默认值为空白
% \abstracttitleb{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的英文摘要

% 设置英文摘要页面的论文标题及副标题的第一行。
% 此属性可选，其默认值为使用|\englishtitle|命令所设置的论文标题
\englishabstracttitlea{A Research on Network Infrastructures}
% 设置英文摘要页面的论文标题及副标题的第二行。
% 此属性可选，其默认值为空白
\englishabstracttitleb{for Data Centers}






\begin{filecontents*}{temp1.tikz}
\begin{tikzpicture}
    \matrix(dict)[matrix of nodes, %below=of game,
        nodes={align=center,text width=20em,text height=5em},
        %row 3/.style={nodes={text height =1em}},
        %column 1/.style={nodes={text width=10cm,align=right}}
    ]{
        $u, w_1, w_2, w_3, \dots, {x}, \dots$ & $x, \dots, w_3, w_2, w_1, u, \dots$ \\
       $v, w^\prime_1, w^\prime_2, w^\prime_3, \dots,{x}, \dots$  & $x, \dots, w^\prime_3, w^\prime_2, w^\prime_1, v, \dots$ \\
       %(a): walk starting from u and v & (b) reversed walks starting from x \\
       %(a) & (b) \\
    };
\end{tikzpicture}
\end{filecontents*}

\begin{filecontents*}{temp2.tikz}
		\begin{tikzpicture}[baseline=0pt]
			\begin{scope}[every node/.style={circle,draw,inner sep=0.5pt,minimum size=10pt}, treenode/.style = {circle,draw,inner sep=0.5pt,minimum size=10pt,fill=gray}]
			    \node (d) at (0,0) {d};
			    \node [treenode] (u) at (1,0) {u};
			    \node (e) at (2, 0) {e};
			    \node (f) at (3,0) {f};
			     \node (a) at (0.5, 0.5) {a};
			    \node (b) at (1.5, 0.5) {b};
			    \node (c) at (2.5, 0.5) {c};
			    \node (v) at (1, 1) {v};
			\end{scope}
			\begin{scope}[
			             every node/.style={fill=black,circle},
			              every edge/.style={draw=black}]
			    \path [->] (v) edge  (a);
			    \path [->] (v) edge  (b);
			    \path [->] (v) edge  (c);
			    \path [->] (a) edge  (d);
			    \path [->] (a) edge  (u);
			    \path [->] (b) edge  (e);
			    \path [->] (b) edge  (u);
			    \path [->] (c) edge  (f);
			    \path [->] (d) edge  (u);
			    \path [->] (e) edge  (f);
			\end{scope}
		\end{tikzpicture}
\end{filecontents*}

\begin{filecontents*}{temp3.tikz}
		\begin{tikzpicture}[baseline=0pt,->,
		level/.style={sibling distance = 3em/#1,level distance = 1.8em}, 
		interestnode/.style = {circle,draw,fill=gray,inner sep=0.5pt,minimum size=10pt},
		treenode/.style = {circle,draw,inner sep=0.5pt,minimum size=10pt}] 
		\node [treenode] {v}
		    child{ node [treenode] {a} 
		             child{ node [treenode] {d} 
									child{ node [interestnode] {u}}			
		            }
		            child{ node [interestnode] {u}}                    
		    }
		    child{ node [treenode] {b}
		            child{ node [treenode] {e} 
									child{ node [treenode] {f}}			
		            }
		            child{ node [interestnode] {u}}
		    }
		    child{ node [treenode] {c}
		    	  child{ node [treenode] {f} 
		     }
			  }
		; 
		\end{tikzpicture}
\end{filecontents*}

\begin{filecontents*}{temp4.tikz}
  \begin{tikzpicture}[auto, 
%fill=white,
node distance=4cm,
%minimum width=3cm,
font=\small]
  
  
\node[initial,state] (A)                                    {$G_0$};
\node[ellipse (4 and 5), minimum=3cm]         (B) [above right of=A]                 {$G_1$};
\node[ellipse (3 and 2) minimum=2cm]         (C) [below right of=A]                 {$G_2$};
\node[state, minimum=1cm]         (D) [below right of=B]                 {$G_3$};
\node[state]         (E) [above right of=D]                 {$s_4$};
\node[state]         (F) [below right of=D]                 {$s_5$};

 

  \end{tikzpicture}
\end{filecontents*}


\begin{filecontents*}{temp5.tikz}
\begin{tikzpicture}
\tikzset{vertex/.style = {shape=circle,draw,minimum size=10 pt}}
\tikzset{edge/.style = {-,> = latex'}}
% vertices
\node[vertex] (a) at  (0,0) {a};
\node[vertex] (b) at  (0,1) {b};
\node[vertex] (c) at  (1,0) {c};
\node[vertex] (d) at  (1,1) {d};

\node[vertex] (i) at  (3,1) {i};
\node[vertex] (j) at  (4,0) {j};
\node[vertex] (k) at  (4,1) {k};
\node[vertex] (l) at  (3,0) {l};

\node[vertex] (e) at  (1.5,2) {e};
\node[vertex] (f) at  (2.5,2) {f};
\node[vertex] (g) at  (1.5,3) {g};
\node[vertex] (h) at  (2.5,3) {h};
%edges
\draw[edge] (b) to (a);
\draw[edge] (b) to (c);
\draw[edge] (a) to (d);
\draw[edge] (b) to (d);
\draw[edge] (c) to (a);
\draw[edge] (c) to (d);

\draw[edge] (e) to (h);
\draw[edge] (e) to (f);
\draw[edge] (e) to (g);
\draw[edge] (f) to (h);
\draw[edge] (f) to (g);
\draw[edge] (g) to (h);

\draw[edge] (i) to (l);
\draw[edge] (i) to (k);
\draw[edge] (i) to (j);
\draw[edge] (l) to (k);
\draw[edge] (l) to (j);
\draw[edge] (j) to (k);


\draw[edge] (f) to (i);
\draw[edge] (d) to (e);
\draw[edge] (c) to (l);
\end{tikzpicture}
\end{filecontents*}

\begin{filecontents*}{temp6.tikz}
\begin{tikzpicture}
\tikzset{vertex/.style = {shape=circle,draw,minimum size=10 pt, fill=gray}}
\tikzset{edge/.style = {-,> = latex'}}
% vertices
\node[vertex] (a) at  (0,0) {$c_1$};
\node[vertex] (b) at  (2.5,0) {$c_2$};
\node[vertex] (c) at  (1.25,2) {$c_3$};
%edges
\draw[edge] (b) to (a);
\draw[edge] (b) to (c);
\draw[edge] (a) to (c);
\end{tikzpicture}
\end{filecontents*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% 制作国家图书馆封面（博士学位论文才需要）
\makenlctitle
% 制作中文封面
\maketitle
% 制作英文封面
\makeenglishtitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 开始前言部分
\frontmatter


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 论文的中文摘要
\begin{abstract}
复杂网络的研究可上溯到20世纪60年代对ER网络的研究。90年后代随着Internet
的发展，以及对人类社会、通信网络、生物网络、社交网络等各领域研究的深入，
发现了小世界网络和无尺度现象等普适现象与方法。对复杂网络的定性定量的科
学理解和分析，已成为如今网络时代科学研究的一个重点课题。

在此背景下，由于云计算时代的到来，本文针对面向云计算的数据中心网络基础
设施设计中的若干问题，进行了几方面的研究。………………
% 中文关键词。关键词之间用中文全角分号隔开，末尾无标点符号。
\keywords{小世界理论；网络模型；数据中心}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 论文的英文摘要
\begin{englishabstract}

% 英文关键词。关键词之间用英文半角逗号隔开，末尾无符号。
\englishkeywords{Small World, Network Model, Data Center}
\end{englishabstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 论文的前言，应放在目录之前，中英文摘要之后
%
\begin{preface}

作为刻画事物之间连接关系的重要数据结构，图在现代社会中很多领域有着广泛
的运用。例如，在互联网、社交网络、物联网、电子商务中，相同或不同实体之间的
关系都可以使用图来刻画。进一步地，如何从图中挖掘出更深层次的信息也成了网络时代科学研究的一个重要课题。
而随着技术的发展，现实问题中图的规模在剧烈的增长，传统的单机算法已经无法在有效时间内完成计算需求。

在此背景下，由于大数据时代的到来，本文针对图中节点相似性SimRank的分布式计算问题，进行了几方面的研究。
本文的创造性研究成果主要如下几方面：

\begin{enumerate}
\item 针对单源点SimRank相似度的计算，提出一种基于随机游走的分布式计算方法。
整个算法主要有两个步骤：先生成生成随机游走，再对游走进行匹配计算其对应概率，
最后汇总得出相似性。设计了一些优化方法来加速算法，包括
减少随机游走的数量，使用更紧凑的数据结构来压缩中间数据，以及通过动态规划
的技巧加速随机游走。本文还对算法的复杂度给出了详尽的分析。

\item 提出一种分布式图分割算法，该算法能够对对图进行尽量均匀的分割，同时最小化分割之间
边的数量（或权重）。实验表明：该分割方法具有较高的效率，同时拥有较高的分割质量，稠密的子图
往往可以处在统一分割中。

\item 基于上诉的图分割方法，提出一种计算所有节点之间相似度的分布式计算方法。该方法使用分而治之的思想，
先计算局部稠密子图的相似性，然后把原先图的每个划分当做新的节点形成一个Coarsen Graph，重新计算这个图的
节点相似性，然后使用这两个局部相似性估算出原图中所有节点的相似性。

\item 对上诉算法，给出在流行的通用计算平台Spark上的分布式实现，并使用真实的数据集
在分布式集群验证算法的精度，效率，以及可扩展性。

\end{enumerate}


\vspace{1cm}
\begin{flushright}
高兴坤\\
2018年夏于南京大学
\end{flushright}

\end{preface}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 生成论文目次
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 生成插图清单。如无需插图清单则可注释掉下述语句。
\listoffigures

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 生成附表清单。如无需附表清单则可注释掉下述语句。
\listoftables

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 开始正文部分
\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 学位论文的正文应以《绪论》作为第一章
\chapter{绪论}\label{chapter_introduction}
\section{研究背景与意义}

图作为一种刻画实体之间关系的重要数据结构，在很多领域中有很多的应用。例如，
电子商务中商品与用户之间的交易行为，科学论文领域中各种论文之间的相互参考应用，
Web 中个网页之间的链接，以及社交网络中用户之间的好友等等行为，本质上都可以
通过基于图来建模。因此，如何从图中挖掘出深层次的信息也成了产业界以及学术界的一个重要课题。

在信息检索，社交网络分析，推荐系统等多个领域，进行相似性度量，即比较不同对象之间的相似度，
是一个重要的课题。SimRank算法是近年来比较流行的一种度量图中节点相似性的模型，与传统方法不同的是
它考虑了整个图的拓扑结构，其基本思想与著名的网页排序算法PageRank有相似之处：
如果两个节点的邻居节点非常相似，那么这两个节点也相似。SimRank模型可以通过随机游走理论解释，
研究表明，它能更准确地衡量相似性。

然而，随着互联网技术的发展，现在已经进入大数据时代。社交网络用户的爆发性增长，电子商务的日益普及，
使得现实生活中图数据的规模越来越大。而传统的SimRank算法具有较高的时间复杂度和空间复杂度，
已经无法适应如今大规模图的分析要求。传统的SimRank计算，包括三个问题：1、单节点对的相似度计算
2、单源点的相似度计算 3、全节点对的相似度计算。这三个问题的复杂度依次增加，由计算图中某一堆节点的相似度，
到图中某节点到其他所有节点的相似度，再到图中所有点对的相似度。

另一方面，诸如MapReduce、Spark等通用式的分布式计算平台充分使用了分布式集群的威力，
用户可以快速部署，然后使用其提供的编程范式专注与自己的计算任务，而无需关系分布式平台底层的复杂网络通信、资源分配、资源调度问题。
在这些平台上设计出高效的分布式算法，具有现实意义。目前现有的计算方法主要是基于矩阵计算，而对于节点数超过百万的大图，
其邻接矩阵的元素规模超过万亿，面对如此庞大的输入规模，普通的矩阵计算方法根本不可行。


针对上述问题，本文提出基于Spark平台的分布式算法，以解决大规模图的SimRank计算问题。本文重点研究第二类与第三类计算问题，
单源点相似性计算以及全节点对的相似性计算，设计在准确率、计算效率以及可扩展性的分布式算法。


\section{相关工作}
为了方便叙述， 我们用$n$表示输入图的节点个数，用$m$表示图的边的个数，用$d$表示图中节点的平均度数。 
对于迭代算法，使用$k$表示算法需要迭代的次数。

\textbf{基于矩阵乘法的计算方法}。 Jeh和Widom提出了第一个基于矩阵乘法的SimRank迭代计算方法，改算法计算全点对的相似性，其复杂度为$O(kn^2d^2)$
.[9]随后通过剪纸、局部访问等技术在矩阵乘法层面将算法的时间复杂度提升到$O(kn^2d)$。【10】使用了快速矩阵乘法来加速计算过程。
文献【12】进一步将算法的时间复杂度提高到$O(kn^2d^{\prime})$,其中$d^\prime < d$。
文献【13】提出了一种基于Keonecker乘积和矩阵奇异值分解（SVD）的非迭代算法，该算法首先在$O(r^4N^2)$时间内计算一些出辅助矩阵，其中$r$是
输入图的领接矩阵的秩，然后再在$O(r^4N^2)$时间内获取给定源点与其他所有节点的相似性。
文献【14】使用了GPU来加速矩阵的计算速度。
对于单点对的SimRank计算，文献【11】给出了一个时间复杂度为$O(kd^2\cdot \min{\{n^2, d^k\}}$的算法。
文献【15】进一步地通过使用概率方法将时间复杂度提高到$O(km^2-m)$。

\textbf{基于随机游走的计算方法}。
图中节点$v$,$u$的相似性，可以解释为：以节点$u$和节点$v$分别为初始点，同步移动的随机游走第一次在某个节点相遇的概率的期望值。
文献【16】给出了第一个基于随机游走的算法， 该算法首先建立一个大小为$O(nN)$的$N$个随机游走的“指纹”索引，然后基于索引查询单点对的相似性。
文献【17】提出一种在随机游走中使用采样技巧计算单点对相似性，该方法在允许一定精度损失的情况下提高了计算效率。
文献【18】研究了图中top-$k$个最相似点对的查询问题，其中$k$往往是一个非常小的值。
该方法把单点对相似查询问题转变为规模为$G\times G$的乘积图上的查询问题。

\textbf{分布式计算方法}。 文献【19】提出了一种基于增量变化的$Delta-SimRank$算法。该算法发现，SimRank可以改写为一种迭代的增量计算方式，
即迭代过程中，不直接改变点对之间的相似性而是计算相对于上一轮迭代的增量。该方法充分利用了迭代计算过程中很多点对间相似性增量为0的事实，减小了
计算过程中的数据传输量。
文献【20】提出了一种基于Spark平台的分布式计算方法，该方法打破了计算点对相似性之间的递归依赖关系：首先线下计算一个不变矩阵$D$，然后线上根据$D$使用
蒙特卡洛方法快速给出查询。然而，$D$的计算被当做一个解线性方程组的过程，这在分布式环境下非常低效，因此虽然算法线上查询的效率很高，
但线下预处理的时间开销非常巨大。

\begin{enumerate}

\item 针对单源点SimRank相似度的计算，提出一种基于随机游走的分布式计算方法。
整个算法主要有两个步骤：先生成生成随机游走，再对游走进行匹配计算其对应概率，
最后汇总得出相似性。设计了一些优化方法来加速算法，包括
减少随机游走的数量，使用更紧凑的数据结构来压缩中间数据，以及通过动态规划
的技巧加速随机游走。本文还对算法的复杂度给出了详尽的分析。

\item 提出一种分布式图分割算法，该算法能够对对图进行尽量均匀的分割，同时最小化分割之间
边的数量（或权重）。实验表明：该分割方法具有较高的效率，同时拥有较高的分割质量，稠密的子图
往往可以处在统一分割中。

\item 基于上诉的图分割方法，提出一种计算所有节点之间相似度的分布式计算方法。该方法使用分而治之的思想，
先计算局部稠密子图的相似性，然后把原先图的每个划分当做新的节点形成一个Coarsen Graph，重新计算这个图的
节点相似性，然后使用这两个局部相似性估算出原图中所有节点的相似性。

\item 对上诉算法，给出在流行的通用计算平台Spark上的分布式实现，并使用真实的数据集
在分布式集群验证算法的精度，效率，以及可扩展性。

\end{enumerate}

\subsection{现有解决方法的不足}

\begin{table}
  \centering
  \begin{tabular}{cccp{38mm}}
    \toprule
    \textbf{文档域类型} & \textbf{Java类型} & \textbf{宽度(字节)} & \textbf{说明} \\
    \midrule
    BOOLEAN  & boolean &  1  & \\
    CHAR     & char    &  2  & UTF-16字符 \\
    BYTE     & byte    &  1  & 有符号8位整数 \\
    SHORT    & short   &  2  & 有符号16位整数 \\
    INT      & int     &  4  & 有符号32位整数 \\
    LONG     & long    &  8  & 有符号64位整数 \\
    STRING   & String  &  字符串长度  & 以UTF-8编码存储 \\
    DATE     & java.util.Date & 8 & 距离GMT时间1970年1月1日0点0分0秒的毫秒数 \\
    BYTE\_ARRAY & byte$[]$ & 数组长度 & 用于存储二进制值 \\
    BIG\_INTEGER & java.math.BigInteger & 和具体值有关 & 任意精度的长整数 \\
    BIG\_DECIMAL & java.math.BigDecimal & 和具体值有关 & 任意精度的十进制实数 \\
    \bottomrule
  \end{tabular}
  \caption{测试表格}\label{table:test1}
\end{table}

\subsection{本文工作的中心观点与思想}
分析已有的计算方法我们可以发现，现有的主流方法在计算全点对相似性时，往往基于矩阵计算；计算单源点相似性时，大多采用随机游走的思想。
然而大多数方法都是传统的单机计算方法，对于大规模的输入图无能无力。 另一方面，现有的分布式算法基本也采用了矩阵计算的思路，而对于一个节点
数目为百万级别的图，其矩阵的元素基本在万亿级别以上。面对如此大的计算规模，即便分布式处理也非常吃力。

因此，




\section{技术背景}
\subsection{Spark背景}
Aparch Spark 是由美国UC Berkeley AMP Lab开发的通用分布式计算引擎，
目前它已经成为Apache Software Foundation下以及同类大数据开源项目中最受关注的项目之一。
Spark遵循类似于MapReduce的编程范式，但是在执行效率上，
Spark改进了Hadoop[14]批处理框架在迭代计算与交互式处理方面的不足，引入了RDD（弹性分布式数据集）的概念，
允许将计算的中间结果保存在内存之中而无需写入磁盘，大大改善了迭代计算的效率，应用程序的性能得到数十倍甚至百倍的提升；
在用户易用性上，Spark支持Java, Scala, Python等主流编程语言，提供了更加丰富的编程API；
在通用性上，Spark针对不同的开发需求提供了更高阶的库，包括SQL查询，流式计算，机器学习算法以及图计算等等，
开发者可以根据自己的需要，单独或组合使用这些库来处理复杂的数据分析任务。
目前，Spark已经成长为包含Spark SQL，Spark Streaming, MLlib, GraphX等多个子项目的完善的生态系统。
使用Spark，用户只需调用编程接口来实现自己的数据计算任务，而无需关心数据的具体分布、并行调度策略、集群节点之间的数据传送与错误恢复等复杂的底层细节。
凭借其高效、用户友好、通用的优点，Spark在学术界和工业界得到了广泛的实际应用。
\begin{figure}[htbp]
  \centering
  \includegraphics[width= 0.7\textwidth]{figure/spark_stack.png}\\
  \caption{Spark系统架构}\label{fig:spark_stack}
\end{figure}
\subsection{Spark系统构架}
一个典型的Spark集群通常包括以下几个组件：
1)Driver Program, 每一个Spark应用程序都包含一个driver program，它执行用户的main函数，并负责在集群调度所有的并行化操作。
当应用程序刚从客户端提交上来的时候，Driver Program需要连接到负责分配整个集群上各种资源的Cluster Manager，并向其请求集群上能够使用的Executor。 
然后，Driver Program会把应用程序的Jar包发送给这些Executor，计算过程中会将计算Task分配给这些Executor。
2)Cluster Manager, 它是向集群申请各种资源的一个额外的服务。Spark支持Mesos, YARN等等。
3)Executor, 它是运行在集群中每一个Worker Node上的一个进程，负责本节点上数据的读写以及各种计算。
\begin{figure}[htbp]
  \centering
  \includegraphics[width= 0.7\textwidth]{figure/spark_components.png}\\
  \caption{Spark系统架构}\label{fig:spark_components}
\end{figure}
\subsection{Spark数据模型}
Spark采用了一种被称为弹性分布式数据集（RDDs, Resilient Distributed Datasets）的分布式数据抽象，它支持工作集的重用，同时拥有非循环数据流模型（acyclic data flow model）的优点，即数据的负载均衡、位置感知和容错机制。同时RDD是一种受到限制的抽象，这体现在它是只读的，并且只能由已有的分布式数据集或其他RDD执行转换操作来创建。通过递归式地保存自己与其ParentRDD之间的转换记录(lineage)，当发生数据分区丢失时RDD可以利用这些记录重新进行计算，快速地恢复数据。
RDD的缺点是它只能提供粒度较粗的转换(coarse-grained transformation)并且它是只读的，这对于一些需要频繁更新数据集的一部分的应用，可能会带来性能上的不足。矩阵计算就是一个需要频繁更新矩阵本身的操作，因此实现算法时要格外注意如何解决这个问题。
RDD可以调用的操作包括转换(transformation)和动作(action)两类。每一个转换操作都会基于调用它的一个或多个parentRdd产生一个新的RDD，所有的转换操作都是懒惰(lazy evaluation)的，这意味着用户在一个RDD上调用一个转换操作并不会立即执行，Spark只是把它当作matadata记住了这些操作。只有当该RDD执行动作操作时，Spark才会利用这些metatada自后往前地追踪到当前RDD最古老的parentRDD，然后从前往后顺序计算这些RDD之间的转换。Spark提供了多种多样的转换，例如map, mapPartitions, union, join, filter等等。
动作(action)指的是需要向driver program返回计算结果或需要将数据导出至存储系统的一类操作。每一个动作都会生成一个Job，对数据进行计算并将计算结果返回给driver。Spark同样提供了多种多样的动作,例如reduce，collect, count， saveAsTextFile等等。
\begin{figure}[htbp]
  \centering
  \includegraphics[width= 0.7\textwidth]{figure/rdd_dependency.png}\\
  \caption{Spark系统架构}\label{fig:rdd_dependency}
\end{figure}
\subsection{Spark常用编程接口}
Spark提供的编程接口，主要包括两类：转化和动作。
其中，典型的转化包括以下几类： 
\begin{enumerate}
 \item {\asciifamily map}一个RDD可以通过map将RDD中的每一个元素通过用户指定的函数转化为另一种类型的元素，
 也就是将原来的RDD转变为指定类型的RDD。map函数接受的参数是一个函数算子。
 \item {\asciifamily mapValues}与map类似，mapValues用于类型为(key, value)的PairRDD。不同的是mapValues不改变元素的key而只改变元素的value，
 因此新的RDD会保留原RDD的partitioner。
 \item {\asciifamily mapPartitions}与map类似，它的第一个参数是一个函数，但mapPartitions是对原RDD的每一个partition而不是每一个element实施这个函数；它的第二个参数是一个Boolen类型，当原RDD的元素类型为(key, value)键值对，并且mapPartitions操作不会改变元素的key时，
 将第二个参数设为true告诉Spark不要改变RDD的partitioner。
\item {\asciifamily filter}一个RDD可以通过filter对RDD中的所有元素按照一定条件进行过滤,过滤后的元素组成一个新的RDD。因此，filter函数接受的参数是一个返回类型为Boolean的函数，这个函数指明一个元素能不能通过筛选。
\item {\asciifamily join}两个元素类型为(key, value)的PairRDD可以通过join操作将双方key相同的元素合并，返回一个新的RDD。
\item {\asciifamily union}两个RDD可以通过union操作合并为一个RDD。
\item {\asciifamily reduceByKey}一个PairRDD调用这个操作可以将原RDD中key相同的若干元素规约为一个元素，返回一个新的RDD。它的第一个参数是一个函数，这个函数相当于元素之间的运算符；第二个可选的参数可以指定新RDD的partition个数。类似于Hadoop中的combiner，spark在shuffle之前会首先对每个计算节点本地的元素先进行合并，从而减小shuffle的开销。
\end{enumerate}
典型的动作包括以下几类：
\begin{enumerate}
 \item {\asciifamily reduce} 它的参数是一个满足交换律、结合律的二元运算符，原RDD的所有元素经过这个运算符计算，返回一个最终值。
 \item {\asciifamily collect} 它将RDD中所有元素从集群上以一个数组的形式返回到Driver Program。collect是一个开销非常大的操作，只适合在小数据集上调用。
\end{enumerate}
还有一种比较特殊的广播操作。通常来说，当集群中的某个节点计算过程中发现需要使用用户自定义的变量时，会向driver program请求将该变量传送到该节点，每一个节点单独地对本地的变量副本进行计算，计算过程中对该副本做出的改动并不会反映到driver program。Spark提供了一种广播变量（broadcast variable）， 
它允许开发者主动地将可能在在节点用到的变量广播到集群中的每个节点上，而不用在程序执行过程中当特定节点发现要使用这个变量再从driver program发送到这个节点上。Spark在传送广播变量时使用了一些高效的算法，减少了广播过程中的通信开销。文献[15]表明，在进行迭代计算时，广播变量能极大地提高整体性能。

\subsection{GraphX背景}
GraphX[todo]是Spark生态圈中的一个核心组件， 主要用于图并行计算。
它提供对图计算和图挖掘简洁易用的而丰富的接口，极大的方便了对分布式图处理的需求
GraphX通过引入一个新的图抽象来拓展Spark中的RDD: Resilient Distributed Property Graph，一种点和边都带属性的有向多重图
这里的属性(property)指的是用户自己定义的描述边或定点某些性质的对象。
一个典型的属性图中包含了描述节点信息的VertexRDD和描述边信息的EdgeRDD。
对属性图的所有操作，最终都会转换成其关联的VertexRDD和的EdgeRDD上的相关操作。
这样对一个图计算任务，最终在逻辑上，等价于一系列RDD的转换过程。因此，Graph最终具备了RDD的3个关键特性：Immutable、Distributed和Fault-Tolerant，其中最关键的是Immutable（不变性）。逻辑上，所有图的转换和操作都产生了一个新图；物理上，GraphX会有一定程度的不变顶点和边的复用优化，对用户透明。
\begin{figure}[htbp]
  \centering
  \includegraphics[width= 0.7\textwidth]{figure/property_graph.png}\\
  \caption{一个简单的属性图。左图为图的拓扑信息及其关联的属性；右图为该属性图底层存储的RDD}\label{fig:property_graph}
\end{figure}
\subsection{GraphX编程范式}
\section{论文结构}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{SimRank原理及技术背景}\label{chapter_smallworld}
\section{SimRank}
为了方便描述，首先给出一些通用的符号定义。本文使用关系$(V, E)$表示一个图，其中 $V$ 图的节点集合， $E \subseteq V \times V$ 是图中边的集合。
$n$ 和 $m$分别是图中节点的个数、边的个数。节点$u$ 称作节点 $v$的入邻点（或出邻点），当且仅当$(u, v)$(或$(v,u)$) 是 $G$中的一条边。
节点$u$ 的所有入邻点用符号 $I(u)=\{v: (v, u) \in E\}$ 表示，所有出邻点用符号  $O(u)=\{v: (u, v) \in E\}$表示。图中所有节点的平均入度（同样也是出度）用符号$d$表示。
节点$u, v$的间的相似性由$s(u, v)$表示，相应的，所有点对的相似度可以写作 $n\times n$的相似度矩阵$S$，并且有$s(u, v)=s_{uv}$。

SimRank是一个基于结构上下文的相似度模型，它的核心思想是：如果两个节点的邻居节点非常相似，那么这两个节点也相似。节点$u, v$间的相似值用数学公式如下表达：
\begin{equation}
s(u, v) = \left\{
        \begin{array}{ll}
	1, & \quad u = v ; \\
	\displaystyle\frac{c}{|I(u)||I(v)|}\displaystyle\sum_{u^\prime \in I(u), v^\prime \in I(v)} s(u^\prime, v^\prime), & \quad u \ne v.
        \end{array}
    \right.
	\label{eq:one}
\end{equation}
其中，$0 < c < 1$ 衰减系数，用以提高临近结构对最终相似性的贡献权重，而降低更远结构的贡献权重。
文献【1】证明了，上面的式子总是存在唯一的解，并且基于SimRank的定义，提出了一种基于矩阵乘法的迭代算法。
设 $S^k$是相似度矩阵$S$在第$k$轮迭代中的计算结果，$S^0$为矩阵初始值，并且如果$u = v$ ，有$S_{uv} = 1$，否则$S_{uv} = 0$。
则矩阵$S^{k+1}$的计算方式如下：
\begin{equation}
S^{k+1}_{uv} = \left\{
        \begin{array}{ll}
	1, &\hspace{-0.5em}  \! u = v ; \\
	\displaystyle\frac{c}{|I(u)||I(v)|}\displaystyle\sum_{u^\prime \in I(u), v^\prime \in I(v)} S^{k+1}_{u^\prime v^\prime} , & \hspace{-0.5em} u \ne v.
        \end{array}
    \right.
	\label{eq:two}
\end{equation}
文献【1】已经证明，$\lim_{k\to\infty}S^k_{uv} = s(u,v)$。可以看出，该算法的时间复杂度为$O(n^2)$， 空间复杂度为$O(kn^2d^2)$ time.

SimRank的另一个模型是基于随机游走模型。节点序列$W=v_0v_1v_2\dots v_l$ 如果对任意$0 \leq i \leq l-1$都满足 $(v_i, v_{i+1})$ 都是 $G$ 中的边，
则称其为 $G$中的一个游走。如果$W$还满足以下的Markov条件，即下式对所有的$i \geq1$ ,   $v_0, v_1, \dots, v_i \in V$成立：
\begin{eqnarray}
\label{eq:three}
  Pr(X_i = v_i|X_{0} = v_{0},\dots, X_{i-1}  = v_{i-1}) \nonumber \\  
 =  Pr(X_i = v_i|X_{i-1} = v_{i-1})
\end{eqnarray}
其中，$X_i$ 表示在第$i$部，游走正好到达的节点。
对任意$ u,v \in V$， $Pr(X_i=v|X_{i-1}=u)$表示在第$i-1$步到达节点$u$的随机游走将在第$i$步到达节点$v$的条件概率。
对于SimRank问题，每一条随机游走从某个节点出发，然后顺着图$G$中的逆变，每一个步骤随机走向该节点的某一个入邻点，并且特别的，转移概率定义为
\begin{equation}
Pr(X_i=v_i|X_{i-1}=v_{i-1}) = \left\{
        \begin{array}{ll}
	\frac{1}{|I(v_{i-1})|}, & \quad (v_i, v_{i-1}) \in E; \\
	0,  &\quad otherwise.
        \end{array}
    \right.
	\label{eq:four}
\end{equation}
相应地，一条随机游走的概率，定义为：
 \begin{equation}
Pr(W) = \prod_{i=1}^{l}Pr(X_i=v_i|X_{i-1}=v_{i-1})
	\label{eq:seven}
\end{equation}
现在假设图$G$中有两条随机游走以相同速度分别从节点$u$和节点$v$同时出发，每次都顺着图中的逆边移动，也就是从当前所在节点移动到下一个入邻点，
并且这两条随机游走在同一个节点$x$相遇并且为初次相遇，我们就把这两条终止在节点$x$的游走称作“匹配游走”。
每一对匹配游走的长度就等于随机游走的步骤数。我们基于此定义相遇概率：
 \begin{equation}
Pr\big((W_u, W_v)\big) = Pr(W_u)Pr(W_v)
	\label{eq:five}
\end{equation}
文献【1】表明，节点$u,v$之间的相似度$s(u,v)$等于服从上面概率分布的若干匹配游走的均值：
 \begin{equation}
s(u,v) = \sum\limits_{W_u, W_v} c^lPr\big((W_u, W_v)\big)
	\label{eq:six}
\end{equation}
其中， ($W_u$, $W_v$) 是一对任意的匹配游走，$l$是游走的长度，$c$是前文定义的衰减系数。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{分布式单源点相似度计算方法}\label{chapter_sssSimRank}

基于以上的SimRank定义以及其基于随机游走模型的解释，计算单源点相似度 $s(u,*)$是非常直接的。
直觉上讲，$s(u,*)$的计算过程可以分解为对$G$中所有节点$v$计算$s(u,v)$的过程。而要计算$s(u,v)$，
我们首先要找出分别从节点$u$和节点$v$出发的所有匹配游走，然后聚合这些游走计算出它们的相遇概率。
注意到想要枚举出任意长度（包括正无穷）的随机游走显然是不可行的，并且显然考虑的长度越长，最后计算得到的相似性越精确。
现实应用中，我们考虑长度为$k$的游走得到的数值可以满足一般应用。
\section{算法中心思想}
文献【11】给出了一个计算单点对SimRank相似度的spSimRank算法。算法的核心思想是两个随机冲浪者分别从节点$u,v$出发，
每一步跟随所在节点的入边；每经过一个节点$t$，原来的随机游走会产生$|I(t)|$ 个新的游走。这样的话经过$k$步游走之后，总共会产生
$O(d^k)$ 个不同的游走，每条随机游走的长度不超过$k$。这些游走使用了一个叫做Path-Tree的数据结构来保存。然后对两个path-Tree中的所有随机游走
进行匹配过程，找出其中的匹配游走。显然与基于矩阵迭代计算的计算方式相比，该算法不需要考虑图中所有的节点。如果我们从这个算法出发，
可以轻易得出一个通过暴力枚举求单源点SimRank相似度的算法。

\begin{figure}
\begin{algorithm}[H]
\captionof{algorithm}{Naive Single-source SimRank:nssSimRank}
\label{algo:nssSimRank}
\begin{algorithmic}[1]
\Procedure{SingleSourceSimRank}{$G, u, k$}
	\For{$ l =1$ to $k$}
		\State $W_u[l] \gets $ all walks of length $l$ starting from $u$;
	\EndFor
	\For {$v \in V(G)$}
		\State $s(u,v)\gets$  \Call{spSimRank}{$G, W_u[], v, k$};
	\EndFor
	\State \textbf{return} $s(u, *)$.
\EndProcedure
\Procedure{spSimRank}{$G, W_u[], v, k$}
\State $s(u, v) \gets 0$;
\For{$ l =1$ to $k$}
	%\State $W_u[l] \gets $ all walks of length $l$ starting from $u$;
	\State $W_v[l] \gets $ all walks of length $l$ starting from $v$;
	\State $s_l(u, v) \gets 0$;
	\For{ $w_u$ in $W_u[l]$}
		\For{ $w_v$ in $W_v[l]$}
		\If {$w_v$ and $w_u$ first meet at index $l$}
			\State add  $score(w_u, w_v)$ to  $s_l(u, v)$;
			\State {\Comment{According to Eq. (\ref{eq:six})}}
		\EndIf
		\EndFor
	\EndFor
	\State add $s_l(u, v)$ to $s(u, v)$;
\EndFor
\State \textbf{return} $s(u, v)$.
\EndProcedure
\end{algorithmic}
\end{algorithm}
\end{figure}
然而，直接通过多次调用spSimRank来计算单源点相似性有以下的缺点：

\begin{enumerate}

\item 总共生成了$O(nd^k)$个游走，但其中大多数的游走都不能匹配到主游走

\item 尽管Path-Tree这种数据结构已经非常高效，但是考虑到会生成$n$个Path-Tree，空间复杂度仍然比较高。
在分布式环境下，因为需要频繁交换节点的局部拓扑信息，这回引起较高的网络开销。

\item 在最后的额匹配过程，统一长度的任意随机游走是以暴力方法匹配的，时间复杂度较高

\end{enumerate}

\section{算法的优化}
\subsection{减少随机游走的数量}
如果直接使用spSimRank算法，总共会生成$O(nd^k)$条随机游走，如果可以将系数$n$减少到某个值$c$使得$C \ll n$，那么游走的数量会极大地减少。
\begin{definition}[倒叙游走]
 我们直接定义随机游走的系列的倒叙序列为倒序游走。
\end{definition}
显然，原始的随机游走与其倒序游走存在一一对应关系。注意到随意游走是在$G$中跟随入边生成的，相应的，倒序游走跟随出边生成。
并且，倒序游走的转移概率需要调整为
\begin{equation}
Pr(X_i=v|X_{i-1}=v_{i-1}) = \left\{
        \begin{array}{ll}
	\frac{1}{|I(v_{i})|}, & \quad (v_{i-1}, v_i) \in E; \\
	0,  &\quad otherwise.
        \end{array}
    \right.
	\label{eq:eight}
\end{equation}

基于倒序游走的定义，可以观察到有下列现象：
\begin{fact}
假设两个分别从节点$u, v$开始的随机游走$W_u, W_v$经过$l$步后在节点$x$相遇，那么如果我们从节点$x$ 出发生成所有长度为$l$的倒序游走，
$W_u, W_v$ 的倒序游走一定也在其中
\end{fact}
\begin{fact}
 假设$W_u=uw_1w_2\dots w_l$是一条主游走，则所有有可能与$W_u$在 $l$步相遇的从游走，只能在$\{w_1, w_2, \dots, w_l\}$中的任意一点相遇。
 也就是说，设$Nei$是节点$u$在$k$部可达的点集，那么只要生成从$Nei$出发的倒序游走就可以计算$s(u,*)$。
\end{fact}

以上两个事实的正确性是显然的。可以看出，总共需要生成的倒序游走的数量大约在$O(|Nei|d^k)$而不是暴力算法的$O(nd^k)$。
事实上， $|Nei|$ 的复杂度为$O(d^k)$， 远比图$G$中点数目小，并且独立于$G$真实大小。

\begin{figure}[t]
\centering
\label{fig:graph1}
\resizebox{!}{!}{\input{temp1.tikz}}
\caption{The left are two walks starting from $u$ and $v$ respectively, first meeting at $x$; the right are reversed walks starting from $x$, passing $u$ and $v$ respectively.}\label{fig:one}
\end{figure}


\begin{figure}[t]
    \centering
    %\subfig[fjalkf]
    \begin{subfigure}[b]{0.48\linewidth}        %% or \columnwidth
        \centering
        \label{fig:match_walks_one}
	\resizebox{!}{!}{\input{temp2.tikz}}
	\caption{$N_G(v, 4)$.}
	
	\end{subfigure}
    \begin{subfigure}[b]{0.48\linewidth}        %% or \columnwidth
     \centering
	\resizebox{!}{!}{\input{temp3.tikz}}
	\caption{Path-tree of $N_G(v, 4)$.}
	\label{fig:match_walks_two}
    \end{subfigure}
    \caption{(a) A neighborhood of $v $.  (b) The corresponding Path-Tree representation of the neighborhood.}
    \label{fig:match_walks}
\end{figure}

\subsection{压缩中间数据的表示}
相比于尽管生成游走的减少了很多，但是$O(d^k)$复杂度依旧很高。
而这些游走序列之间会有很多前缀子序列高度重合，如果单独地保存每一条游走，那么整个存储会有较大的冗余。
TODO
为了解决多个游走序列共享很多前缀子序列，对$|Nei|$中的每一个节点$v$，我们并不使用任何特别设计的数据结构单独存储从$v$的所有随机游走，
而是直接使用从$v$开始跟随逆边$k$可达的一个邻域$N_{G}(v, k)$。
严格的说，$N_{G}(v, k)$是节点从$v$跟随逆边$k$步可达的节点集合在$G$中的生成子图。
例如，在图【4】中，展示了$v$的一个邻域。他所对应的path-tree显示在右图中，灰色的节点是我们欲查询的节点$u$。
可以看到，$N_{G}(v, k)$自己本身就是Path-Tree的一种压缩表示。
显然，我们在这一步中没有显式地表示出每一条游走，是因为在分布式环境中生成游走的过程需要在不同的计算节点上传输$G$中的局部拓扑信息，
如果中间传输数据量过大，那么网络开销会极大地影响算法的最终性能。我们在下面会详细叙述即使没有显式表示每一条游走，算法仍然可以高效地计算出最终结果。

\subsection{使用动态规划技巧加速随机游走的匹配}
当$Nei$中的每个节点$v$收集到了从它自己开始的倒序游走$N_{G}(v, k)$之后，这些从游走需要与主随机游走$N_{G}(u, k)$进行匹配，从而得到最后的结果。
由于代表所有主游走的$N_{G}(u, k)$只是一个很小的信息($O(d^k)$)，我们可以把它预先广播到分布式集群中的每一个节点上。
而所有的从游走$N_{G}(v, k)$按照$v$作为key分不到不同的节点上，然后每个计算节点直接在本地进行匹配过程。
正因为这样，算法中最耗时的匹配部分是分布到每个计算节点上进行的，这是我们设计该算法的主要目的。

为了方便叙述，我们以在节点$v$第一次相遇的随机游走为例。
注意整个匹配过程中，我们只对与主游走在$v$相遇，但是之后再也不和主游走有任何共同节点的逆序游走感兴趣。
例如，在\ref{fig:match_walks_two}中，路径$vau$和$vbe$是一对对$s(u,e)$有意义的匹配游走。
同理，和$vau$能匹配上的随机游走还包括$vau$和$vcf$。
但是，$vad$和$vau$不是一对合法的匹配游走，因为它们首次在节点$a$而不是$v$首次相遇。实际上，
$vad$和$vau$同样对$s(d,u)$的计算做出了贡献，但是在分布式环境下，这个计算过程是由形如图\ref{fig:match_walks_two}、但root
节点为$a$的Path-Tree引导的。这个计算过程也应当发生在该Path-Tree的计算节点上。
基于以上的简单观察，可以发现以下事实：
\begin{fact}
如果我们的查询节点$u$处于某个Path-Tree的某一层里，那么那一层的其他任一满足$LCA(u, w)=v$的节点$w$都会对节点$u,w$的相似度$s(u,w)$的计算做出
大小为$c^{l}Pr(W_u)Pr(W_w)$的贡献，其中$LCA$指的是最近公共祖先(Lowest Common Ancestor)，
$W_u, W_w$是由对应Path-Tree展开的root-to-node路径。
\end{fact}
我们使用DFS算法来搜索整个领域$Nei_v$。　
在DFS过程中，每一条root-to-node路径的概率被记录下来。
当DFS的深度达到$l$时，算法停止，对应逆序游走的概率被保存在一个HashMap中。
当我们再次匹配长度为$l+1$的主游走时，就不再需要从节点$v$开始我们的DFS过程，因为该Path-Tree中长度小于等于$l$的逆序游走的概率之前已经全部计算过了。
例如，在图\ref{fig:match_walks_two}中，能和游走$vbdu$匹配的唯一游走是$vbef$，而计算$vbef$的概率时，我们只需要从节点$e$开始DFS过程，
因为$vbe$的概率在之前搜索$vae$的匹配游走时已经计算被保存过了。

因此为了克服多个游走之间共享了很多重复前缀这一问题，我们把匹配游走这一问题看做是一个动态规划(Dynamic Programming)问题，
通过Memorization的技巧来降低匹配的时间复杂度。算法的具体细节在\ref{alg:dp}中列出。
程序LevelMatch展示了一个Path-Tree中的根节点$v$如何寻找一个长度为$l$的主游走。
各参数的意义如下：$W_l$是长度为$l$的主游走的集合；$N$是从节点$v$开始展开的领域；$M_{l^\prime}$ 
保存了之前调用LevelMatch函数来匹配长度为$l^\prime$主游走得到的匹配概率，具体地说它是一个(key,value)形式的HashMap,
其中key是$v$的邻居节点，表示该k-v对保存的是以Path-Tree中第二层节点为根节点的哪一棵子树的信息，
value是一串元素，每个元素记录着以$key$为根节点的子树中所有的游走的终止节点以及对应游走的概率；
类似的$M_l$是一个将要被填充的空的HashMap，保存匹配长度为$l$的游走的匹配概率；
最后一个参数$\delta$是一个概率阈值，其具体的含义将在下一节给出。
我们首先循环$W_l$中的每一条主游走$p$，并且知道该主游走在Path-Tree中的哪一棵子树中（2-3行），如果$M_l$中没有记录该子树中匹配游走的概率，
就开始DFS过程（４行）。
我们先检查$W_｛l\prime｝$中是否有记录该子树的信息，如果有的话就直接从记录的游走的终止节点开始调用DFS(5-6行），
否则就需要从该子树的根节点开始DFS。
程序DFS就是一个常见的DFS过程。
通过对所有的$W_l, (l \leq k)$，所有游走的匹配概率都可以高效地计算出来。


\begin{figure}
\begin{algorithm}[H]
\captionof{algorithm}{Dynamic Programming Path Matching}
\label{alg:dp}
\begin{algorithmic}[1]
\Procedure{LevelMatch}{$W_l, N, v, M_{l^\prime}, M_l, \delta$}
	\For {$p \in W_l$}
		\State {$br \gets$ second last vertex of $p$};
			\For {$t \in (v_N.neighbors - br)$ \& $t \notin M_l$}
				
					\If {$!M_{l^\prime}$.contains$(t)$}
						\State \parbox[t]{\dimexpr\linewidth-\algorithmicindent} {\Call{DFS}{$N, t, l, M_l,\delta, t, 1, 1$};}	
					\Else 
						\For {$w \in M_{l^\prime}$}
							\For {$nei \in w_N.neighbors$}
								\State \parbox[t]{\dimexpr\linewidth-\algorithmicindent}{\Call{DFS}{$N, nei, l,M_l,\delta,br,w.mul, l^\prime$};}
							\EndFor
						\EndFor
					\EndIf			
				
			\EndFor
	\EndFor
	\State \textbf{return} $M_l$.
	%\State \textbf{return} $results$.
\EndProcedure
\Procedure{DFS}{$N, v, l, M,\delta ,br ,mul,depth$}
	\State {$mul \gets mul * v_N.indegree$};
	\If {$mul > \delta$}
		\State \textbf{return;} \Comment{Early termination.}
	\EndIf
	\If {$depth = l$}
		\State {add $(v, mul)$ to $M(br)$};  \Comment{Record  probability.} %to the branch it resides in.}
	\Else
		\For {$nei \in v_N.neighbors$}
			\State \parbox[t]{\dimexpr\linewidth-\algorithmicindent} {\Call{DFS}{$N, nei, l, M,\delta, br,mul$, $ depth+1$};}
		\EndFor
	\EndIf
	\State \textbf{return} $M$.
\EndProcedure
\end{algorithmic}
\end{algorithm}
\end{figure}
\subsection{使用概率阈值剔除极小的概率}
很多现实的大图都是scale-free【２１】的，这意味这图中的极小比例的节点会有极高的度数。
我们的算法的性能与节点的度数紧密相关，因为在生产游走过程中每条游走每经过一个度数为$d$的节点，都会在那个节点分裂为$d$条更长的游走。
因此，我们使用一个阈值$\delta$来删除那些包含多个拥有极高度数的节点的游走，因为根据公式【ＴＯＤＯ】，这些游走对的概率非常之小，
对最终的计算精度基本可以忽略不计。$\delta$的取值应当注意在算法的精度与时间、空间复杂度取得平衡，更大的$\delta$意味着更低的精度，当时算法
整体的时间复杂度和空间复杂度更低，反之反是。
\section{算法的复杂度分析}
我们综合分析一下算法的复杂度。源点$u$可达的节点的数目大约为$O(d^k)$，
而对于其中的每一个可达节点，都拥有一个大小为$O(d^k)$，隐式包含$O(d^k)$条逆序游走信息的领域，
因此，总的空间复杂度为$O(d^{2k})$。因为这个过程中所有产生的游走都需要通过网络传输，所以通信开销也是$O(d^{2k})$。
在对游走进行匹配时，对每一个领域，大约有$O(d^k)$个游走被匹配了，所以总的计算复杂度为$O(d^{2k})$。
可以看到，算法总的复杂度与整个图的规模$O(n+m)$没有以来关系，所以我们的算法是非常高效的。
\section{基于Spark平台的实现}

\section{实验评估}
本章节重点描述
\subsection{实验环境}
所有的实验在一个由6个硬件完全相同的计算节点组成的集群上完成，每台计算节点处理器为12核的Intel Xeon E-2650，频率为2.1GHz，
内存为64GB，硬盘为1TB。 计算节点之间由千兆网卡连接。所有的节点上运行Ubuntu 16.04操作系统。 
Spark运行版本为1.6.2， 底层分布式文件系统HDFS的版本号为2.6.0。
所有的6个节点都配置为slave节点，其中一个节点被二外配置为master节点。 
在Spark运行时，我们为其分配了10GB的内存。
\subsection{实验数据集}
我们一共使用了5个真实的图数据来评估算法的性能。 数据集的具体细节如表\ref{tab:dataset1}。
每个图一开始为普通的文本形式，每一行代表这图中的一条边。
在开始实验前，所有的数据集都预先上传到分布式文件系统HDFS上。
\begin{table}[h]
\caption{数据集描述}
\label{tab:dataset1}
\centering
\begin{tabular}{|l|r|r|r|r|}
\hline
\textbf{数据集} & \textbf{顶点数} & \textbf{边数} & \textbf{顶点平均度数} & \textbf{大小} \\
\hline
p2p-gnutella08 \footnotemark[1]  & {6,301}         & \num{20777}                   & 3.29                & 215.2KB\\
\hline
wiki-vote \footnotemark[2]    & 7,115 	& \num{103,689}                           &14.57                & 1.1MB  \\
\hline
%wiki-talk            & \num{2394385} & \num{5021410}          &2.10                   & 66.5MB\\
%\hline
eu-2005       \footnotemark[3]     & \num{862664}  & \num{19235140 }          & 22.29             & 256.4MB\\
\hline
ljournal-2008  \footnotemark[4] & \num{5363260} & \num{79023142}         & 14.73            &1.2GB\\
\hline
arabic-2005 \footnotemark[5]   & \num{22744080} & \num{639999458}      & 28.14           & 10.9GB\\
%\hline
%twitter-2010    & \num{41652230 } & \num{1468365182} & 26.1GB\\
\hline
\end{tabular}
\end{table}
\subsection{实验参数设置}
根据文献文献【9】中的描述，通常算法所需要的最大迭代次数$k$是由衰减系数$c$和算法的预期精度决定的。 
如果希望最终误差 $s^*(u,v) - s^k(u,v)$小于某个$\epsilon$，那么$k$至少要被设置为$k=\lfloor \log_c \epsilon \rfloor$。
在我们的实验中，我们选取$\epsilon=0.01$，因为这样的精度可以满足大多数实际应用。 
$c$被设置为0.5，相应的，$k$被设置为$k=6$。

此外，用于过滤掉极小概率的游走的阈值被设置为$\delta=0.002$。主要到这里的$\delta$指的是一个随机游走的概率阈值，
根据\ref{eq:five}对于一对匹配好的游走，其对应的匹配概率相应的变成${\delta}^2$。
如果再考虑到因子$c^l$，那么这个概率是极端小的，完全可以忽略。

算法精度的测试采用的方法是多次实验取平均值，每次实验时随机选取图中的某个顶点为查询顶点。
具体的，对与小图（大小<10MB），我们重复实验100次计算其平均值；对于更大的图，重复次数设为1000。
\subsection{算法有效性}
\begin{figure*}[t]
\centering
\begin{subfigure}[b]{0.48\textwidth}
	\center
	\includegraphics[width=1\textwidth]{figure/accuracy1.eps}
	\caption{p2p-gnutella08}
	\label{fig:ch1:effec:one}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
	\centering
	\includegraphics[width=1\textwidth]{figure/accuracy2.eps}
	\caption{wiki-vote}
	\label{fig:ch1:effec:two}
\end{subfigure}
\label{fig:ch1:effec}
\caption{apSimRank和sssSimRank的相似性误差随迭代次数的变化曲线比较}
\end{figure*}
我们首先比较我们的算法和全点对算法的精度和收敛速度。
我们选取的精度指标为平均误差(mean error)，即$ME = \frac{1}{n}\sum_{v \in V}{\left|s(u,v) - s^k(u,v)\right|}$，
其中$s(u,v)$为根据\ref{eq:two}迭代计算至完全收敛的真实相似性，$s^k(u,v)$为我们算法迭代$k$次后的相似性。
我们在两个小图上进行实验。其中p2p-gnutella08是个比
较稀疏的图，平均顶点度数$d=3.29$，而wiki-vote是一个更加稠密的图，平均顶点度数为$d=15.57$。
图\ref{fig:ch1:effec}为最终的比较结果。
从图中可以看到，全点对算法和我们的算法在6次迭代以内精度都得到了收敛， 我们的算法sssSimRank有更好的收敛速度，三次迭代之后平均误差就在$10^{-4}$以内。
另一个现象是在图\ref{fig:ch1:effec:one}中sssSimRank的平均误差与apSimRnak的差距比图\ref{fig:ch1:effec:two}更小，
这是因为我们的算法中使用了概率筛除的缘故。对于同一个概率阈值$\delta$，图的平均顶点度数越大，小概率游走越多， 相应的，被剔除的小概率游走越多，
所以对最终精度的影响越来越大。 本质上，$\delta$的作用是牺牲一定的精度来换取计算效率的提高。
即便如此， sssSimRank的相似性误差仍然非常小（$<10^{-4}$）， 完全可以满足大部分应用的精度需求。
\subsection{算法的效率}
为了比较算法的运行效率，我们分别基于Spark平台实现了分布式的全点对算法apSimRank， \ref{algo:nssSimRank}算法nssSimRank，以及本文提出的算法sssSimRank。
直接比较这三个算法的运行时间非常困难，因为apSimRank以及nssSimRank实际运行非常耗时，
在规模最小的图p2p-gnutella08上， apSimRank需要运行2.1个小时才能完成计算，而nssSimRank需要计算1.2个小时。
因为对于基于随机游走模型的算法而言，其运行效率主要取决于所生产的随机游走的数量，进一步地说，取决于需要从多少个领域$Nei$来展开生产随机游走。
因此，我们比较sssSimRank和nssSimRank算法中生产$Nei$的数量。结果如图\ref{fig:ch1:runtime}所示。
\begin{figure}[htbp]
  \centering
  \includegraphics[width= 1\textwidth]{figure/neighborhoods.eps}\\
  \caption{生成领域数量的比较}\label{fig:ch1:runtime}
\end{figure}
从图中可以看出，sssSimRank极大地减少了生成领域的数量。
当$\delta=0$时，即算法没有筛除概率极小的游走时，领域数量减少了大约1500x倍。
从图中还可以观察到领域数量与概率阈值$delta$之间的关系。
当$\delta$越来越大时，意味这概率“筛子”的“孔”变得越来粗，幸存的随机游走会变得越来越少。
图\ref{fig:ch1:runtime}还表明，图eu-2005和arabic-2005减少领域的比例比图p2p-gnutella08和ljournal-2008要大很多，
这一观察同样表明算法中的概率筛子对稠密的图能更好地提高性能。
\subsection{算法的可扩展性}
我们考察分布式环境下算法的可扩展性。 首先考察算法运行时间随着输入图的大小的变化关系，结果如图\ref{fig:ch1:data_scalable}所示。
\begin{figure}[htbp]
  \centering
  \includegraphics[width= 1\textwidth]{figure/data_scalability.eps}\\
  \caption{算法运行时间与输入图大小的变化关系}\label{fig:ch1:data_scalable}
\end{figure}

图中展示了当集群计算节点数目固定时，对于不同的$\delta$，运行时间随输入图规模大小变化的情况。 
可以看出，输入图的规模从215KB到10.9GB，而对应的运行时间基本上近似的随着输入规模大小线性的变化，
这一结论对不同的$\delta$都成立。这展示出sssSimRank良好的数据可扩展性。
我们还考察了当输入图的规模固定时，算法运行效率随集群中计算节点数量变化的情况。
所有的输入图使用同样的参数配置，$k=6$， $\delta=10^{-4}$。 计算节点数量从2增加到6。
注意到我们把$\delta$取得非常小，是因为$delta$越小，算法剔除的游走越少，算法的计算量越大。
这样更能提现计算量较为饱和的情况下算法的节点可扩展性。实验结果如图\ref{fig:ch1:node_scalable}所示。
从图中可以看到，对不同规模的输入图，算法的运行时间随集群计算节点的增加而近乎线性的减少，
这表面算法在分布式环境下具有良好的节点可扩展性。
\begin{figure}[htbp]
  \centering
  \includegraphics[width= 1\textwidth]{figure/node_scalability.eps}\\
  \caption{算法运行时间与集群计算节点数量的变化关系}\label{fig:ch1:node_scalable}
\end{figure}

\section{小结}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{分布式图分割方法}\label{chapter_graphpartition}
为了计算图$G$中所有节点的相似度，我们将在下一章节介绍cSimRank算法。 而本章节主要介绍一种分布式的图分割算法，它是cSimRank的中间步骤。
作为一种常见的基础算法， 目前已经有大量的工作对图分割做了各种形式的研究。 文献【23】证明了，图分割是$NP$完全问题。
而对于目前不断增长的大图来说， 图分割问题面临着许多新的挑战：
\begin{enumerate}
 \item 真实的图拓扑结构往往节点分布极不规则，这往往使得并行算法或分布式算法无法拥有很好的并发度或并行度
 \item 真实图的节点的度数往往表写出非常倾斜的分布，这使得不同处理器上的负载无法均衡
\end{enumerate}
针对以上问题，我们提出一种高效的分布式图分割算法， 实验结果表面， 该算法具有较高的效率，较好的可扩展性。

\section{图分割概述}
对于大规模图而言， 图分割意味着把图中的节点划分为不同的分割，并将其存储在集群中不同的计算节点上去。
在这个过程中， 为了能够访问到非局部的拓扑信息， 网络开销是必不可少的。 换句话说，采取什么样的方法对图分割，
对分割过程中的网络开销和负载均衡有种决定性影响。
\section{相关工作}
目前针对图分割的一些研究，主要有以下几种
\textbf{单节点串行算法} 文献【23】证明了图分割问题是一个NP完全问题。 因此，早起很多工作都集中在设计一些近似算法以求得次优解。
文献【5】提出了KL算法，该方法将图划分为偶数个划分，基于一些启发式的信息不断交换不同划分对中的节点， 使得不同划分之间的边割($edge-cut$)的权重最小；
类似的方法还有文献【6】研究了FM算法。还有一些基于模拟退火【24】，遗传算法【25】的解决方案。这些方法研究的都是基于内存的小图。
为了能够应对更大规模的图，一些多层次分割的方法相继被提出，包括 Metis[8]Chaco[7]和Scotch[10]。
这些方法的主要思想是首先将局部的某些节点变为一个节点，从而提取出整个图拓扑信息的“骨骼”，这一过程成叫做”塌缩“（coarse）; 
这样图的规模得到了不断的缩小，当规模达到某个可以接受的规模后， 然后再使用传统的KL或FM算法对其进行处理；
然后通过一个“uncoarse”的过程还原出原来的图。

\textbf{单节点并行算法} 为了进一步充分利用现代CPU的多核特性，从以上这些算法中演化出一些并行化算法，例如ParMetis[11], Pt-Scotch[12]等。 
因为这些方法中有部分步骤可以并行，所以其能够处理的图的规模也获得了的提高。 
然而总的来说，这些方法仍然是基于单计算节点的， 对规模更大的（上百万节点）图无能为力。

\textbf{分布式图划分} 近年来，一些专门用于图计算的分布式平台越来越流行，包括Pregel[15]，Giraph[X]，Spark GraphX[TODO]等等。
这些平台的一个重要特点是支持以节点为中心(vertex-centric)的编程范式，　并且支持节点之间的消息通信。　
在处理图计算问题时，这些平台内部默认地使用了简单的随机划分方法，其中一些也开放了一些接口支持用户设计按照需求设计自己的分割方法。　
但是并没有提供一个能够使用的图分割算法。

\section{算法的基本框架}
我们从以下两方面来考虑图划分算法的优化目标：
\begin{enumerate}
 \item 最终划分结果的负载均衡。 考虑一个由$k$个硬件条件完全相同的计算节点组成的集群，因为存储资源（硬盘）存在于每个计算节点上，
 所以理想情况下最终划分的结果应当尽可能的均匀分布在集群中。也就是说，每个划分的大小应当在$\frac{|V|}{k}$左右，
 或者说划分过程中应该避免规模大于$\frac{|V|}{k}$的分块的产生。如果仍然有某个分块分布式地存储在超过一个结算节点上，那所谓的图划分就没有意义。
 \item 最终划分结果的质量。 理想情况下	图划分算法应该可以把图中稠密的子图归类于一个分块中。但是因为有负载均衡的限制，
 而图中稠密子图的规模天然是不均匀的，因此我们从整体考虑划分的质量。设$C$是图$G(V,E)$的一个划分，定义其权重为
 $W_{P}=\sum\nolimits_{e(u,v) \in E, u \in C_i, v \in C_j} w\big(e(u,v)\big)$，即所有连接不同分块的边的权重之和。
 理论上，$W_P$应尽可能的小。
\end{enumerate}


我们的算法借鉴了图塌缩的思想，　即通过不断的coarsen使得原来的图的规模越来越小，当图的规模小到某个条件时，再使用KL或FM处理。
METIS是这种多层次图分割算法的典型代表。　它主要有三个步骤，　首先对原图进行反复的塌缩，然后对获得的图进行划分，然后再进行反塌缩过程恢复出对原图的划分。
第一个步骤，METIS使用寻找最大匹配（maximaｌ match)的方法来对原图进行coarsen。形式上说，一个最大匹配就是一个包含做多边的集合，使得集合中每条边的不存在重合的节点。
最大匹配中的每条边都可以塌缩为新图$G\prime_1$中的一个节点，这样图的规模就能不断的减小。第二步骤中，直接使用ＫＬ或ＦＭ对$G\prime_k$进行划分；
最后一个步骤中，$G\prime_k$的划分被重新映射到原图$G$中去。
我们给出算法的基本框架:
\begin{figure}
\begin{algorithm}[H]
\captionof{algorithm}{Multi-Level Graph Partitioning}
\label{alg:mlgp}
\begin{algorithmic}[1]
\Procedure{MultiLevelGraphPartition}{$G, \alpha, \beta, k$}
	\While{\#partitions $\ge \alpha$}
		\State $P \gets $ results of modularity-based community detection for $\beta$ iterations;
		\State Construct $G\prime$ from $P$; \Comment{Coarsen.}
	\EndWhile  
	\State $P_1 \gets $ Run local graph partitioning on $G\prime$. \Comment{Final refinement.}
	\State restore partition $P\prime$ from $P_1$ \Comment{Project back to the orignal graph.}
\EndProcedure
\end{algorithmic}
\end{algorithm}
\end{figure}
算法包含三个参数，$\alpha, \beta, k$。
其中，$\alpha$指的是反复塌缩过程的目标划分数目，如果迭代过程中当前的划分数目大于$\alpha$，就继续迭代下去。
实际应用中， $\alpha$的取值与第二步中单节点图划分算法可以处理的输入图规模有关。
$\beta$指的是我们基于模量的塌缩方法的迭代次数。
$k$是集群中计算节点的个数。

\subsection{图的塌缩}
文献【ＴＯＤＯ】给出了一种基于标签传播（Label Propogation，　LP)的分割思想。　
ＬＰ算法一开始被运用于社区发现，即在图$G$中将不同的节点划分为不同的社区，每个社区的内部节点往往连通得比较紧密，　社区之间的节点往往连通比较稀疏。
这种方法天然地借鉴到图划分问题中，因为在图划分问题中，往往也要求每一个分块之间的节点紧密连通，而不同划分之间应该较少连通或理想状况下不连通。　
ＬＰ算法的思想非常简单：最初的时候我们给每个节点一个单独的社区ID, 然后我们迭代式地为每个节点更新社区ＩＤ。每次迭代中，每个节点按照其邻居节点中出现最多的社区ＩＤ
作为自己的社区ＩＤ。当$G$中每个节点的社区ＩＤ基本上不再变动时，算法结束。
上述算法并没有使用$G$中任何的先验信息或者是前置的目标函数，因此有很搞的提升空间。我们这里借鉴了文献【７】中的模量的思想，
即在迭代过程中有方向性地寻找合适的社区ＩＤ。
我们首先给出如下定义
设关系$(V, E)$表示一个图，其中 $V$ 图的节点集合， $E \subseteq V \times V$ 是图中边的集合。
$n$ 和 $m$分别表示图中节点的个数、边的个数。　$d_v$表示节点$v$的度数, $c_v$表示节点$v$所在社区的ＩＤ。
这样根据文献【ＴＯＤＯ】中的定义，　一个无向连通图的模量定义如下：
\begin{equation}\label{eq:modularity}
Q = \frac{1}{2m}\sum\limits_{u, v \in V} \left[w_{uv} - \frac{{d_u}{d_v}}{2m} \right]\delta(c_u, c_v),
\end{equation}
其中$\delta(c_u, c_v)$表示节点$u, v$是否处于一个社区，即如果$c_v = c_u$，　那么$\delta(c_u, c_v)$等于１；否则为０。
按照上面的定义，我们有如下的定理：

\theorem{根据上面的定义，我们实际上可以得到模量$Q$定义的简单形式：
\begin{equation}
Q = \sum\limits_{c \in C} \left[\frac{I_c}{2m} - {\left(\frac{S_c}{2m}\right)}^2 \right]
\end{equation}
}
其中，　$I_c$表示ＩＤ为$c$的社区中两个定点都在$c$中的边的数量，　而$S_c$表示社区$c$中所有节点的度数的综合，
即$S_c = \sum\limits_{v \in V} {d_v}$
\begin{proof}
假设$c$是图$G$中的某个划分，　根据\label{eq:modularity}的定义，我们知道如果节点$u, v$属于不同的社区的话，那么显然有$\delta(c_u, c_v)=0$,
因此我们只要考虑属于同一社区的点对就可以了，　即我们可以把\label{eq:modularity}改写为：

\begin{equation}
\begin{aligned}
Q &= \frac{1}{2m}\sum\limits_{u, v \in V} \left[w_{uv} - \frac{{d_u}{d_v}}{2m} \right]\delta(c_u, c_v) \\
& = \frac{1}{2m}\sum\limits_{c \in \mathcal{C}} {\sum\limits_{u, v \in c} { \left[w_{uv} - \frac{{d_u}{d_v}}{2m} \right]}} \\
& = \frac{1}{2m}\sum\limits_{c \in \mathcal{C}} \left[{\sum\limits_{u, v \in c} { w_{uv} - \frac{\sum\nolimits_{i,j \in c}{{d_u}{d_v}}}{2m}}}\right] 
\end{aligned}
\end{equation}
其中，显然我们有$I_c=\sum\nolimits_{u, v \in c}  w_{uv}$, 
并且有$\sum\nolimits_{i,j \in c}{{d_u}{d_v}} =
\sum\nolimits_{u \in c}{d_u} \sum\nolimits_{v \in c}{d_v} = S_c S_c = {S_c}^2$
因此，　我们有如下的定理：
\begin{equation}
\begin{aligned}
Q &= \frac{1}{2m}\sum\limits_{c \in C} \left[I_c - \frac{S_c^2}{2m} \right] \\
& = \sum\limits_{c \in C} \left[\frac{I_c}{2m} - {\left(\frac{S_c}{2m}\right)}^2 \right]
\end{aligned}
\end{equation}
\end{proof}
有了以上的定以后，我们回到算法\label{algo:mlgp}的框架中。
设原始输入图为$G(E,V)$，　并假设迭代塌缩过程中产生的中间图用记号$G_1, G_2, \dots, G_t$表示，　
相应的，　迭代过程中由中间图产生的划分称作$P_1, P_2, \dots, P_{t}$。　
注意到有$P_i \gets G_i$，　即迭代中图划分与其输入是对应的。
然后我们有以下定义：
\begin{definition}
 设基于图$G_i(V_i, E_i)$有划分$P_i=(C_1, C_2, \dots, C_n)$，　基于$P_i$上构造塌缩图$G_{i+1}(V_{i+1}, E_{i+1}$如下：
 令$V_{i+1} = P_i$，　即$P_i$ 中的每一个划分对应$G_{i+1}$中的一个新节点；　边$(C_i, C_j) \in E_{i+1}$当且仅当$\exists
 u \in C_i, v \in C_j$ 并且 $(u, v) \in E_i$。
\end{definition}
\begin{definition}
 设基于图$G_{i+1}$迭代过程中基于图$G_i$生产的压缩图，并且有$V_{i+1}=(C_1, C_2, \dots, C_n)$，
 那么边$e=(C_i, C_j)$的新权重定义为：
 \begin{equation}
w(C_i, C_j) = \sum\limits_{e(u,v) \in E_i, u \in C_i, v \in C_j} w\big(e(u,v)\big)
\end{equation}
即压缩图中的新边的权重等于该边在原图中代表的两个划分中所有相连接的边的权重之和。
\end{definition}


\begin{figure}[t]
    \centering
    %\subfig[fjalkf]
    \begin{subfigure}[b]{0.48\linewidth}        %% or \columnwidth
        \centering
        \label{fig:two:one}
	\resizebox{!}{!}{\input{temp5.tikz}}
	\caption{一个图$G$　}
	\label{fig:figure2:figure1} 
	\end{subfigure}
    \begin{subfigure}[b]{0.48\linewidth}        %% or \columnwidth
     \centering
	\resizebox{!}{!}{\input{temp6.tikz}}
	\caption{经过塌缩后的图$G\prime$}
	\label{fig:figure2:figure2}
    \end{subfigure}
    \caption{(a)为一个简单的示例图，(b)为改图经过塌缩(coarse)后的图$G\prime$, 每个节点代表$G$中的一个划分}
    \label{fig:two}
\end{figure}
我们下面给出基于模优化的图划分方法。
我们首先考虑，假设节点$u$属于划分$c$, 而它的所有邻居节点所属的划分为$C = \{c_1, c_2, c_3, \dots, c_n \}$，
那么对某个$c_i \in C$，如果我们考虑把$u$从$c$中移出，重新放入到$c_i$中，整个图$G$的模量会一次发生变化，我们用符号$\Delta Q_{u,c}$。
并且根据模量的定义，我们有：
\begin{equation}
\begin{aligned}
 \Delta Q_{u,c}=\left[ \frac{I_c+w_{i,c}}{2m} - {\left(\frac{S_c + l_i}{2m} \right)}^2 \right] -
 \left[ \frac{I_c}{2m} - {\left(\frac{S_c}{2m} \right)}^2 - {\left(\frac{l_i}{2m}\right)}^2 \right]
\end{aligned}
\end{equation}
经过若干步骤的化简，最终我们可以得到模量变化的简单形式：
\begin{equation}
\begin{aligned}
 \Delta Q_{u,c}=\frac{w_{i,c}}{2m} - \frac{S_cl_i}{2m^2} 
\end{aligned}
\end{equation}

我们对图进行塌缩的算法如下所示：
%\begin{figure}[tbp]
\begin{algorithm}[h]
\captionof{algorithm}{Modularity-based Graph Coarsening}
\label{alg:mlgp}
\begin{algorithmic}[1]
\Procedure{GraphCoarsening}{$G, \beta$}
	\While{\# iterations $\le \beta$}
	    \State Initialize $\mathcal{C}$, which assigns each node a unique partition identifier;
	    \State $m=\sum\nolimits_{u,v \in V} w_{u,v}$;
	    \For { $u \in V$}
		\State{$maxGain = -1$};
		\For{ $v \in N_v$}
		     \State $\Delta Q_{u,c_{v}}=\frac{w_{i,c}}{2m} - \frac{S_{c_v}l_i}{2m^2}$;
		     \If {$\Delta Q_{u,c_{v}} > maxGain$}
		      \State $maxGain = \Delta Q_{u,c_{v}}$
		      \State newPartition = $n_v$
		     \EndIf
		\EndFor
		\If {$maxGain > 0$}
		    \State $c_{newPartition} \gets c_{newPartition}\cup\{u\}$;
		    \State $c_{u} \gets c_{u} - \{u\}$;
		\EndIf	
	    
	    \EndFor
	\EndWhile
\State \textbf{return} $C$.
\EndProcedure
\end{algorithmic}
\end{algorithm}
%\end{figure}

\subsection{图的划分}
\section{算法的优化}

\section{算法的实现}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{分布式全点对相似度计算方法算法}\label{chapter_allSimRank}
\section{算法框架}
基于章节\ref{chapter_graphpartition}中对图做出的划分，我们现在给出一个计算全点对相似度的近似算法。
文献【11】描述了一种基于图中分块结构（Block Structure）的若干性质来加速计算PageRank的方法，我们的近似算法直接受到了该算法的启发。
对于现实生活中的图数据集，图中天然可以划分为着若干稠密的分块，这些稠密的分块包含了更多节点之间的连接，
因此往往也蕴含着最多的人们感兴趣的信息。本文正是充分利用了这一性质，提出了一种计算全点对相似度计算的近似算法。
相比原来的SimRank的计算方法，该算法不仅极大地提高了计算效率，而且保留了原来的计算精度。

在计算节点对之间的相似性时，节点对可以分为两种：
\begin{enumerate}
 \item 位于同一稠密分块之中的顶点对。 在上一章节中，我们已经详细介绍了将原图$G$划分为若干稠密分块的方法，每一个划分好的
 分块都被存放在集群中的某一个计算节点中。 这种情况下可以\ref{eq:two}中的串行计算方法直接计算出该点对的相似性。
 \item 位于不同分块之中的顶点对。这种情况下，注意到因为两个顶点分别处于不同的稠密分块之中，这意味这两个顶点的距离会以较大概率地比较远，
 也即意味着这两个顶点的相似性会较大概率地在数值上表现得非常之小。这个时候我们通过估算近似地给出最终的相似度。
\end{enumerate}
与上一章节类似，假设图中的每一个分块是一个顶点，那么图的划分就形成了一个塌缩图。
基于这个塌缩图，我们首先定义图中边的权重：
\begin{definition}
 塌缩图中边的权重。 假设对图$G$有划分$P=(C_1, C_2, \dots, C_n)$，
 设$L(C_i)$表示分块$C_i$中所有边的数量，包括该分块内部的边以及连接到其他分块的边;
 $L(C_i, C_j)$表示分块$P_i$与分块$P_j$中相连接的边的数量。
 设图$G^\prime$为划分$P$形成的塌缩图，$v_i \in G^\prime, v_j \in G^\prime$, 
 且$v_i$为分块$C_i$对应的顶点，$v_j$为分块$C_j$对应的顶点。
 那么定义边$(v_i, v_j)$的权重为：
\begin{equation}
 w(v_i, v_j) = \frac{L(C_i, C_j)}{L(C_i)} 
\end{equation}
$v_i$自己到自己的权重定义为
\begin{equation}
 w(v_i, v_i) = 1-\sum_{v_j \in O(v_i)}{w(v_i, v_j)}
 \end{equation}
显然，一般情况下$w(v_i, v_j)$与$w(v_j, v_i)$是不同的。
\end{definition}
这样经过塌缩后的图$G^\prime$变成了一个加权有向图。
边$(v_i, v_j)$的权重可以粗略理解为某个随机游走者从点$v_i$“逃逸”到点$v_j$的概率。
$w(v_i, v_j)$越大，说明在原图$G$中分块$C_i$与$C_j$的交叉边越多，联系越紧密。

基于以上的定义，我们给出图$G$中各个分块之间的相似性定义：
\begin{definition}
 原图$G$有划分$P=(C_1, C_2, \dots, C_n)$，定义分块$(C_i, C_j)$之间的相似性为塌缩图$G^\prime$中顶点$v_i,v_j$之间的相似性。
\end{definition}
我们下面给出加权有向图的顶点相似性计算方法。
 为了将边的权重引入到SimRank模型中，我们使用如下的公式迭代公式计算相似性：
\begin{equation}
  s_{k+1}(u,v) = c \cdot evidence(u,v)  
  \sum_{u^\prime \in I(u), v^\prime \in I(v)} s_{k}(u^\prime, v^\prime)W(u^\prime, u)W(v^\prime, v)
\end{equation}
其中，$c$是衰减系数，并且
\begin{equation}
    evidence(u,v)=\sum_{i=1}^{|I(u)\cap I(v)|}2^{-i} 
   \end{equation}
\begin{equation}
     W(u^\prime, u)=w(u^\prime, u)\cdot \exp(-{Var(\{w(u^\prime,u) \mid u \in O(u^\prime)\}})
\end{equation}

如果写成矩阵的形式，设$V$为evidence矩阵，满足$V(i,j)=evidence(i,j)$，那么整个加权有向图的SimRank相似性计算如下：
\begin{algorithm}[h]
\captionof{algorithm}{Weighted All-pair SimRank:wapSimRank}
\label{algo:wapSimRank}
\begin{algorithmic}[1]
\Procedure{WeightedSimRank}{$G^\prime, u, c, k$}
	\State $N \gets |V|$;
	\State $S \gets$ identity matrix $I_N$;
	\For{$ i =1$ to $k$}
		\State $T \gets c\cdot W^T \cdot S \cdot W$;
		\State $S \gets T + I_N -D(diag(T))$ \Comment{$D$ is the diagnal matrix.};
	\EndFor
	\State $S \gets$ element-wise multiplication of $V$ and $S$
	\State \textbf{return} $S$.
\EndProcedure
\end{algorithmic}
\end{algorithm}
\begin{definition}
 不同分块间点对的相似性。如果点对$(u,v)$的两个顶点分别属于图的不同分块$C_i$和$C_j$之中，
 并且有分块$C_i$与$C_j$的相似性为$s_{block}(C_i, C_j)$，
 我们使用下式来估计其相似性：
 \begin{equation}
 \label{eq:avg}
    s(u,v) = s(C_i, u) \cdot s_{block}(C_i, C_j) \cdot s(C_j, v)
   \end{equation}
  其中，$s(C_i, u)$可以看做顶点$u$与其分块的中心点间的相似度，由下式近似给出：
  \begin{equation}
    s(C_i, u) = \frac{1}{|C_i|}\sum_{q \in C_i}{s(u,q)}
   \end{equation}
   即我们使用$u$与所以与其属于同一个分块的顶点对额相似性的均值来估计$u$到与分块中心的相似度。
\end{definition}
显然，如果由算法\ref{algo:wapSimRank}计算出的分块间的相似度是随着迭代次数收敛的，并且分块内点对的相似度计算过程也是收敛的，
那么由以上式子定义出的分块间点对的相似度也是随着迭代次数收敛的。因此可以分开计算分块之间的相似度与分块内点对的相似度，
最后再基于它们计算分块间点对的相似度。
综上，我们的算法步骤主要如下：
\begin{enumerate}
 \item 首先根据上一章节描述的方法，对原图$G$做划分，得到若干个分块$P=(C_1, C_2, \dots, C_n)$；
 \item 将各个分块当做一个顶点进行塌缩得到一个加权有向图$G^\prime$，在$G^\prime$运行适用于加权图的SimRank算法，得到
 分块之间的相似度；
 \item 对任一分块$C_i$直接运行串行的全点对SimRank算法，得到分块内部的节点对相似度；
 \item 使用公式\ref{eq:avg}估计属于不同分块顶点之间的相似度；
 \item 最后返回全局相似度。
\end{enumerate}
我们综合分析算法的复杂度。simRank以及其适用于加权图的变种的时间复杂度都为$O(kd^2n^2)$。
假设图$G$已经被划分为$m$个分块，则每个分块的大小在$O(n/m)$左右。若
塌缩图$G^\prime$的顶点平均度数为$d_1$，那么第2步的时间复杂度为$O(k{d_1}^2m^2)$。
第3步的时间复杂度为$O(mk{d_2}^2(n/m)^2)$，即$O(k{d_2}^2n^2/m)$，其中$d_2$为每个分块中节点的平均度数。
第4步计算全局相似度时，因为要考虑所有点对，而根据\ref{eq:avg}，平摊之后每对顶点对只需常数级别的查询计算时间，
因此总的时间复杂度为$O(n^2)$。
如果我们考虑主要的计算过程，即第2步和第3步，所需的时间为$O(k{d_1}^2m^2+k{d_2}^2n^2/m)$。
若假设有$d_1=d_2=k$，则时间复杂度为$(kd^2(m^2+n^2/m))$。 
将该复杂度看做变量$m$的函数，则函数在$m=(2n)^{2/3}/2$处有极值，这对我们选择合适的$m$有指导意义。
进一步的，考虑分布式环境下第3步主要由多个计算节点的多个线程同时完成，不妨设总线程数为$T$，
则该函数变为$f(m)=kd^2(m^2+n^2/(Tm)$，其在$m=(n^2/(2T))^{1/3}$处有极值。

\section{基于Spark平台的实现}

我们以ACM Computing Classification System(CCS)中的数据集为例。该数据集是一个揭示计算机科学方向科研论文分类系统。
在CCS数据集第F大类中，总共有6个类别。我们把每一篇论文当做一个顶点，论文之间的引用当做边，那么整个数据集就可以抽象为一个图。
\begin{definition}
 对图G中的两个划分$P_1, P_2$，
\end{definition}
\section{算法理论模型}
\section{算法概览}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 学位论文的正文应以《结论》作为最后一章
\chapter{结论}\label{chapter_concludes}

本文在第\ref{chapter_smallworld}章中，通过考虑数据中心网络布局构建中的最大度限制
问题，提出了符合数据中心网络基本要求的DS小世界模型，并分析了它的性质。随后提出
SIDN，将DS模型映射到具体的网络结构中，并分析了所构成网络的平均直径、网络总带宽、
对故障的容错能力等各项网络性能。

分析与仿真实验证明，SIDN网络具有很好的扩展能力，网络总带宽与网络规模成
近似线性增长的关系；具有很强的容错能力，链路损坏与节点损坏几乎无法破坏
网络的联通性，故障率对网络性能的影响与破坏节点/链路占总资源比率线性相关。

随后在第\ref{chapter_scalefree}章中，分析了无尺度网络在数据中心网络构建应用中的
理论方面问题。对Scafida \cite{gyarmati2010scafida}文中所述在最大度限制的情况下运
用BA算法构造的网络并不会损失无尺度性质的观点，进行了深入的分析，并指出了该论点的
局限性。

在给出了在引入节点最大度限制之后，利用分治和递归的思想，对无尺度网络
进行多层构建，对所构造的网络进行度-度相关性，以及聚类性分析。

\begin{table}
  \centering
  \begin{tabular}{cccp{38mm}}
    \toprule
    \textbf{文档域类型} & \textbf{Java类型} & \textbf{宽度(字节)} & \textbf{说明} \\
    \midrule
    BOOLEAN  & boolean &  1  & \\
    CHAR     & char    &  2  & UTF-16字符 \\
    BYTE     & byte    &  1  & 有符号8位整数 \\
    SHORT    & short   &  2  & 有符号16位整数 \\
    INT      & int     &  4  & 有符号32位整数 \\
    LONG     & long    &  8  & 有符号64位整数 \\
    STRING   & String  &  字符串长度  & 以UTF-8编码存储 \\
    DATE     & java.util.Date & 8 & 距离GMT时间1970年1月1日0点0分0秒的毫秒数 \\
    BYTE\_ARRAY & byte$[]$ & 数组长度 & 用于存储二进制值 \\
    BIG\_INTEGER & java.math.BigInteger & 和具体值有关 & 任意精度的长整数 \\
    BIG\_DECIMAL & java.math.BigDecimal & 和具体值有关 & 任意精度的十进制实数 \\
    \bottomrule
  \end{tabular}
  \caption{测试表格}\label{table:test5}
\end{table}

表\ref{table:test5}用于测试表格。随后分析了无尺度网络构造过程中，交换机节点与数
据节点的角色区别，分析了两者在不同比率下形成的网络形态，以及对网络性能造成的影响。

通过理论分析和仿真实验，分析并找出比率因子q的最佳取值。此外，无尺度现象
的引入提高了网络的聚类系数，从而在不失灵活性可靠性的基础上，进一步提升
了网络的性能。

在第\ref{chapter_random}章中，将关注点转移到交换机本身。由于图论难以描述数据中心
网络中的交换设备，因此放弃基于图的抽象模型，转而基于多维簇划分的思想，提出并设计
了WarpNet网络模型。

该网络模型突破了基于图描述的局限性，并对网络的带宽等指标进行理论分析并
给出定量描述。最后对比了理论分析、仿真测试结果，并在实际物理环境中进系
真实部署，通过6节点的小规模实验以及1000节点虚拟机的大规模实验，表明该模
型的理论分析、仿真测试与实际实验吻合，并在网络性能、容错能力、伸缩性灵
活性方面得到了进一步的提升。

在第\ref{chapter_experiments}章中，针对网络模型研究这一类工作的共性，设计构造通
用验证平台系统。以海量虚拟机和虚拟分布式交换机的形式，实现了基于少量物理节点，对
大规模节点的模拟。其模拟运行的过程与真实运行在实现层面完全一致，运行的结果与真实
环境线性相关。除为本文所涉若干网络模型提供验证外，可进一步推广到更为广泛的领域，
为各种网络模型及路由算法的研究工作，提供分析、指导与验证。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 致谢，应放在《结论》之后
\begin{acknowledgement}
白驹过隙间，我的三年研究生就要结束，我在南京大学七年的学习生活就要画上句号。
在这即将离别校园之际，回想三年的校园生活，很多情景都历历在目。
研究生阶段，我的科研能力得到了提升，生活上也变得更加独立。
在这里我衷心感谢我的导师、师兄弟、同学、朋友们，你们平时对我的教导、支持、帮助让我愉快地走完了这平凡的三年，感谢你们！

首先感谢我的导师唐杰。唐老师为人谦和，工作负责，在学术上对我们都尽心尽力地指导，在生活上对我们也多有照顾。
无论是本课题的研究及论文的撰写，还是平时对我科研能力的塑造，唐老师都以身作则，对我提供了很多帮助。
唐老师宽厚谦和的生活作风也潜移默化地影响着我，指导着我做一个脚踏实地的南大人。

我还要感谢武钢山老师。武老师是多媒体教研室主任，他作风严瑾，要求严格，把握着最新的科研动向，同时管理着整个大组的研究学习工作。
在此特别感谢武老师对我学习和生活上的种种帮助。

还要感谢实验室的师兄师弟以及师妹们。三年以来你们给了我很多的关心和支持，很高兴能和你们同门，你们让我留下了很多美好的回忆。
祝愿两位老师身体健康，万事如意！ 也祝各位同学学业有成，科研顺利！
最后感谢我的家人，他们永远是我最大的支柱和依靠！

\end{acknowledgement}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 附录
\appendix

\chapter{博士(硕士)学位论文编写格式规定(试行)}

\section{适用范围}

本规定适用于博士学位论文编写，硕士学位论文编写应参照执行。

\section{引用标准}

GB7713科学技术报告、学位论文和学术论文的编写格式。

GB7714文后参考文献著录规则。

\section{印制要求}

论文必须用白色纸印刷，并用A4(210mm×297mm)标准大小的白纸。纸的四周应留足空白
边缘，上方和左侧应空边25mm以上，下方和右侧应空边20mm以上。除前置部分外，其它
部分双面印刷。

论文装订不要用铁钉，以便长期存档和收藏。

论文封面与封底之间的中缝（书脊）必须有论文题目、作者和学校名。

\section{编写格式}

论文由前置部分、主体部分、附录部分(必要时)、结尾部分(必要时)组成。

前置部分包括封面，题名页，声明及说明，前言，摘要(中、英文)，关键词，目次页，
插图和附表清单(必要时)，符号、标志、缩略词、首字母缩写、单位、术语、名词解释
表(必要时)。

主体部分包括绪论(作为正文第一章)、正文、结论、致谢、参考文献表。

附录部分包括必要的各种附录。

结尾部分包括索引和封底。

\section{前置部分}

\subsection{封面（博士论文国图版用）}

封面是论文的外表面，提供应有的信息，并起保护作用。

封面上应包括下列内容：
\begin{enumerate}
\item 分类号  在左上角注明分类号，便于信息交换和处理。一般应注明《中国图书资
  料分类法》的类号，同时应注明《国际十进分类法UDC》的类号；
\item 密级  在右上角注明密级；
\item “博士学位论文”用大号字标明；
\item 题名和副题名   用大号字标明；
\item 作者姓名；
\item 学科专业名称；
\item 研究方向；
\item 导师姓名，职称；
\item 日期包括论文提交日期和答辩日期；
\item 学位授予单位。
\end{enumerate}

\subsection{题名}

题名是以最恰当、最简明的词语反映论文中最重要的特定内容的逻辑组合。

题名所用每一词语必须考虑到有助于选定关键词和编写题录、索引等二次文献可以提供
检索的特定实用信息。

题名应避免使用不常见的缩略词、首字母缩写字、字符、代号和公式等。

题名一般不宜超过20字。

论文应有外文题名，外文题名一般不宜超过10个实词。

可以有副题名。

题名在整本论文中不同地方出现时，应完全相同。

\subsection{前言}

前言是作者对本论文基本特征的简介，如论文背景、主旨、目的、意义等并简述本论文
的创新性成果。

\subsection{摘要}

摘要是论文内容不加注释和评论的简单陈述。

论文应有中、英文摘要，中、英文摘要内容应相同。

摘要应具有独立性和自含性，即不阅读论文的全文，便能获得必要的信息，摘要
中有数据、有结论，是一篇完整的短文，可以独立使用，可以引用，可以用于推广。摘
要的内容应包括与论文同等量的主要信息，供读者确定有无必要阅读全文，也供文摘等
二次文献引用。摘要的重点是成果和结论。

中文摘要一般在1500字，英文摘要不宜超过1500实词。

摘要中不用图、表、化学结构式、非公知公用的符号和术语。

\subsection{关键词}

关键词是为了文献标引工作从论文中选取出来用于表示全文主题内容信息款目的单词或
术语。

每篇论文选取3－8个词作为关键词，以显著的字符另起一行，排在摘要的左下方。在英
文摘要的左下方应标注与中文对应的英文关键词。

\subsection{目次页}

目次页由论文的章、节、附录等的序号、名称和页码组成，另页排在摘要的后面。

\subsection{插图和附表清单}

论文中如图表较多，可以分别列出清单并置于目次页之后。

图的清单应有序号、图题和页码。表的清单应有序号、表题和页码。

符号、标志、缩略词、首字母缩写、计量单位、名词、术语等的注释表符号、标志、缩略词、
首字母缩写、计量单位、名词、术语等的注释说明汇集表，应置于图表清单之后。

\section{主体部分}

\subsection{格式}

主体部分由绪论开始，以结论结束。主体部分必须由另页右页开始。每一章必须另页开
始。全部论文章、节、目的格式和版面安排要划一，层次清楚。

\subsection{序号}

\begin{figure}[htbp]
  \centering
  \includegraphics[width= 0.5\textwidth]{njuname.eps}\\
  \caption{测试附录中的插图}\label{fig:appendix1}
\end{figure}

论文的章可以写成：第一章。节及节以下均用阿拉伯数字编排序号，如
1.1，1.1.1等。

论文中的图、表、附注、参考文献、公式、算式等一律用阿拉伯数字分别分章依序连续编排
序号。其标注形式应便于互相区别，一般用下例：图1.2；表2.3；附注1）；文献[4]；式
  (6.3)等。

论文一律用阿拉伯数字连续编页码。页码由首页开始，作为第1页，并为右页另页。封页、
封二、封三和封底不编入页码，应为题名页、前言、目次页等前置部分单独编排页码。页码
必须标注在每页的相同位置，便于识别。

\begin{equation}
    C_i = \frac{2E_i}{k_i(k_i-1)}
\end{equation}

附录依序用大写正体A、B、C、$\cdots$编序号，如：附录A。附录中的图、表、式、参考文
献等另行编序号，与正文分开，也一律用阿拉伯数字编码，但在数码前题以附条序码，如图
A.1；表B.2；式(B.3)；文献[A.5]等。

\subsection{绪论}

绪论（综述）：简要说明研究工作的目的、范围、相关领域的前人工作和知识空白、理
论基础和分析，研究设想、研究方法和实验设计、预期结果和意义等。一般在教科书中
有的知识，在绪论中不必赘述。

绪论的内容应包括论文研究方向相关领域的最新进展、对有关进展和问题的评价、本论
文研究的命题和技术路线等；绪论应表明博士生对研究方向相关的学科领域有系统深入
的了解，论文具有先进性和前沿性；

\begin{problem}
测试定理环境。测试定理环境。测试定理环境。测试定理环境。测试定理环境。测试定理环境。
测试定理环境。测试定理环境。测试定理环境。
\end{problem}

为了反映出作者确已掌握了坚实的基础理论和系统的专门知识，具有开阔的科学视野，对研
究方案作了充分论证，绪论应单独成章，列为第一章，绪论的篇幅应达$1\sim 2$万字，不
得少于$1$万字；绪论引用的文献应在$100$篇以上，其中外文文献不少于$60\%$；引用文献
应按正文中引用的先后排列。

\subsection{正文}

论文的正文是核心部分，占主要篇幅。正文必须实事求是，客观真切，准确完备，合乎
逻辑，层次分明，简便可读。

\begin{figure}[htbp]
  \centering
  \includegraphics[width= 0.5\textwidth]{njuname.eps}\\
  \caption{测试附录中的插图}\label{fig:appendix2}
\end{figure}

正文的每一章(除绪论外)应有小结，在小结中应明确阐明作者在本章中所做的工作，特
别是创新性成果。凡本论文要用的基础性内容或他人的成果不应单独成章，也不应作过
多的阐述，一般只引结论、使用条件等，不作推导。

\subsubsection{图}

图包括曲线图、构造图、示意图、图解、框图、流程图、记录图、布置图、地图、照片
、图版等。

图应具有“自明性”，即只看图、图题和图例，不阅读正文，就可以理解图意。

图应编排序号。每一图应有简短确切的图题，连同图号置于图下。必要时，应将图上的
符号、标记、代码，以及实验条件等，用最简练的文字，横排于图题下方，作为图例说
明。

\begin{example}
测试定理环境。测试定理环境。测试定理环境。测试定理环境。测试定理环境。测试定理环境。
测试定理环境。测试定理环境。测试定理环境。
\end{example}

曲线图的纵、横坐标必须标注“量、标准规定符号、单位”。此三者只有在不必要标明
(如无量纲等)的情况下方可省略。坐标上标注的量的符号和缩略词必须与正文一致。

照片图要求主题和主要显示部分的轮廓鲜明，便于制版。如用放大缩小的复制品，必须
清晰，反差适中。照片上应该有表示目的物尺寸的标度。

\subsubsection{表}

表的编排，一般是内容和测试项目由左至右横读，数据依序竖排。表应有自明性。

表应编排序号。

每一表应有简短确切的表题，连同标号置于表上。必要时，应将表中的符号、标记、代
码，以及需要说明事项，以最简练的文字，横排于表题下，作为表注，也可以附注于表
下。表内附注的序号宜用小号阿拉伯数字并加圆括号置于被标注对象的右上角，如：
xxx${}^{1)}$；不宜用“*”，以免与数学上共轭和物质转移的符号相混。

表的各栏均应标明“量或测试项目、标准规定符号、单位”。只有在无必要标注的情况下
方可省略。表中的缩略词和符号，必须与正文中一致。

表内同一栏的数字必须上下对齐。表内不宜用“同上”，“同左”和类似词，一律填入具体数字
或文字。表内“空白”代表未测或无此项，“－”或“\textellipsis”（因“－”可能与代表阴性
  反应相混）代表未发现，“0”代表实测结果确为零。

如数据已绘成曲线图，可不再列表。

\subsubsection{数学、物理和化学式}

正文中的公式、算式或方程式等应编排序号，序号标注于该式所在行(当有续行时，应
标注于最后一行)的最右边。

较长的式，另行居中横排。如式必须转行时，只能在$+$，$-$，$\times$，$\div$，$<$，
$>$处转行。上下式尽可能在等号“$=$”处对齐。

小数点用“$.$”表示。大于$999$的整数和多于三位数的小数，一律用半个阿拉伯数字符的小
间隔分开，不用千位撇。对于纯小数应将$0$列于小数点之前。

示例：应该写成$94\ 652.023\ 567$和$0.314\ 325$, 不应写成$94,652.023,567$和
$.314,325$。

应注意区别各种字符，如：拉丁文、希腊文、俄文、德文花体、草体；罗马数字和阿拉伯数
字；字符的正斜体、黑白体、大小写、上下脚标（特别是多层次，如“三踏步”）、上下偏差
等。

\subsubsection{计量单位}

报告、论文必须采用国务院发布的《中华人民共和国法定计量单位》，并遵照《中华人
民共和国法定计量单位使用方法》执行。使用各种量、单位和符号，必须遵循附录B所
列国家标准的规定执行。单位名称和符号的书写方式一律采用国际通用符号。

\subsubsection{符号和缩略词}

符号和缩略词应遵照国家标准的有关规定执行。如无标准可循，可采纳本学科或本专业
的权威性机构或学术团体所公布的规定；也可以采用全国自然科学名词审定委员会编印
的各学科词汇的用词。如不得不引用某些不是公知公用的、且又不易为同行读者所理解
的、或系作者自定的符号、记号、缩略词、首字母缩写字等时，均应在第一次出现时一
一加以说明，给以明确的定义。

\subsection{结论}

报告、论文的结论是最终的、总体的结论，不是正文中各段的小结的简单重复。结论应
该准确、完整、明确、精炼。在结论中要清楚地阐明论文中有那些自己完成的成果，特
别是创新性成果；

如果不可能导出应有的结论，也可以没有结论而进行必要的讨论。可以在结论或讨论中
提出建议、研究设想、仪器设备改进意见、尚待解决的问题等。

\subsection{致谢}

可以在正文后对下列方面致谢：

\begin{itemize}
\item 国家科学基金、资助研究工作的奖学金基金、合作单位、资助或支持的企业、组织或个
人；
\item 协助完成研究工作和提供便利条件的组织或个人；
\item 在研究工作中提出建议和提供帮助的人；
\item 给予转载和引用权的资料、图片、文献、研究思想和设想的所有者；
\item 其他应感谢的组织或个人。
\end{itemize}

\subsection{参考文献表}

\subsubsection{专著著录格式}

主要责任者，其他责任者，书名，版本，出版地：出版者，出版年

例：1. 刘少奇，论共产党员的修养，修订2版，北京：人民出版社，1962

\subsubsection{连续出版物中析出的文献著录格式}

析出文献责任者，析出文献其他责任者，析出题名，原文献题名，版本：文献中的位置。

例：2. 李四光，地壳构造与地壳运动，中国科学，1973 (4)：400－429

参考文献采用顺序编码制，按论文正文所引用文献出现的先后顺序连续编码。

\section{附录}

附录是作为报告、论文主体的补充项目，并不是必需的。

下列内容可以作为附录编于报告、论文后，也可以另编成册；

\begin{enumerate}
\item 为了整篇论文材料的完整，但编入正文又有损于编排的条理和逻辑性，这一材料
包括比正文更为详尽的信息、研究方法和技术更深入的叙述，建议可以阅读的参考文献
题录，对了解正文内容有用的补充信息等；
\item 由于篇幅过大或取材于复制品而不便于编入正文的材料；
\item 不便于编入正文的罕见珍贵资料；
\item 对一般读者并非必要阅读，但对本专业同行有参考价值的资料；
\item 某些重要的原始数据、数学推导、计算程序、框图、结构图、注释、统计表、计
算机打印输出件等。
\end{enumerate}

附录与正文连续编页码。

每一附录均另页起。

\section{结尾部分 (必要时)}

为了将论文迅速存储入电子计算机，可以提供有关的输入数据。可以编排分类索引、著者索
引、关键词索引等。

% 参考文献。应放在\backmatter之前。
% 推荐使用BibTeX，若不使用BibTeX时注释掉下面一句。
\nocite{*}
\bibliography{sample}
% 不使用 BibTeX
%\begin{thebibliography}{2}
%
%\bibitem{deng:01a}
%{邓建松,彭冉冉,陈长松}.
%\newblock {\em \LaTeXe{}科技排版指南}.
%\newblock 科学出版社,书号:7-03-009239-2/TP.1516, 北京, 2001.
%
%\bibitem{wang:00a}
%王磊.
%\newblock {\em \LaTeXe{}插图指南}.
%\newblock 2000.
%\end{thebibliography}

% 附录，必须放在参考文献后，backmatter前
\appendix
\chapter{图论基础知识}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 书籍附件
\backmatter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 作者简历与科研成果页，应放在backmatter之后
\begin{resume}
% 论文作者身份简介，一句话即可。
\begin{authorinfo}
\noindent 韦小宝，男，汉族，1985年11月出生，江苏省扬州人。
\end{authorinfo}
% 论文作者教育经历列表，按日期从近到远排列，不包括将要申请的学位。
\begin{education}
\item[2007年9月 --- 2010年6月] 南京大学计算机科学与技术系 \hfill 硕士
\item[2003年9月 --- 2007年6月] 南京大学计算机科学与技术系 \hfill 本科
\end{education}
% 论文作者在攻读学位期间所发表的文章的列表，按发表日期从近到远排列。
\begin{publications}
\item Xiaobao Wei, Jinnan Chen, ``Voting-on-Grid Clustering for Secure
  Localization in Wireless Sensor Networks,'' in \textsl{Proc. IEEE International
    Conference on Communications (ICC) 2010}, May. 2010.
\item Xiaobao Wei, Shiba Mao, Jinnan Chen, ``Protecting Source Location Privacy
  in Wireless Sensor Networks with Data Aggregation,'' in \textsl{Proc. 6th
    International Conference on Ubiquitous Intelligence and Computing (UIC)
    2009}, Oct. 2009.
\end{publications}
% 论文作者在攻读学位期间参与的科研课题的列表，按照日期从近到远排列。
\begin{projects}
\item 国家自然科学基金面上项目``无线传感器网络在知识获取过程中的若干安全问题研究''
（课题年限~2010年1月 --- 2012年12月），负责位置相关安全问题的研究。
\item 江苏省知识创新工程重要方向项目下属课题``下一代移动通信安全机制研究''
（课题年限~2010年1月 --- 2010年12月），负责LTE/SAE认证相关的安全问题研究。
\end{projects}
\end{resume}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 生成《学位论文出版授权书》页面，应放在最后一页
\makelicense

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}

